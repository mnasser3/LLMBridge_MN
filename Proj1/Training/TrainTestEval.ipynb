{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "h1TBE7xXn8Sb"
   },
   "source": [
    "# GENERAL LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QsSsEauaLN5",
    "outputId": "301dcfaf-31d9-4fb8-d3ba-7262f2817c63"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orttIbDvbUX0",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3509b640-5175-494f-cb81-50df2d24fda3"
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install transformers[torch]\n",
    "!pip install transformers peft\n",
    "\n",
    "# !pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "UTv_rzjtNMPD"
   },
   "outputs": [],
   "source": [
    "# NEEDS TO BE PARENT DIRECTORY OF TRAINING\n",
    "dir= '/content/drive/MyDrive/BridgeAthletics/Proj1'\n",
    "sub_dir='/Training/AdvancedData2/'\n",
    "data_sub_dir='/Dataset2_allparams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "1f8126f0-f17b-4523-b604-224100cd72ab"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import torch\n",
    "#import accelerate\n",
    "#from accelerate import Accelerator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "sys.path.append(dir)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from peft import get_peft_model, LoraConfig, LoraModel\n",
    "\n",
    "#CUSTOM FUNCTIONS FROM FUNCTIONS.PY\n",
    "from Training.Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "27b89d49-10f7-4bac-8d40-c87fd4a03306"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, Seq2SeqTrainer, Seq2SeqTrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfYVE42a3m6B",
    "outputId": "52c2a2d7-e929-4611-9817-20be01169d4d"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "QnAvtTLw5hRq"
   },
   "source": [
    "# MODEL + TOKENIZER LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "af896bc7-7749-457a-b385-d0a8da1622d4"
   },
   "outputs": [],
   "source": [
    "#MODEL SELECTION: GPT2\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "TiL9xSQTLdXb"
   },
   "outputs": [],
   "source": [
    "#MODEL SELECTION: T5\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "Nz0O_NSx4Z5q"
   },
   "source": [
    "# DATASET CLASS - FORMATTING + PREPARING FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "958ed0fb-2c2b-4c2a-a5a3-6eacf4ea4e64"
   },
   "outputs": [],
   "source": [
    "class InstructionDataset_GPT2(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        self.instruction_lengths = []\n",
    "        for item in data:\n",
    "            instruction_plus_input = format_model_input(item)\n",
    "            response_text = f\"\\n\\n### Response:\\n{item['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "            instruction_length = len(tokenizer.encode(instruction_plus_input))\n",
    "            self.instruction_lengths.append(instruction_length)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # return self.instruction_lengths[index], self.encoded_texts[index] #(TO USE WITH CUSTOM COLLATE)\n",
    "        return self.encoded_texts[index] #(TO USE WITH TRANSFORMERS COLLATE)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class InstructionDataset_T5(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.inputs=[]\n",
    "        self.labels=[]\n",
    "        for item in data:\n",
    "            instruction_plus_input = format_model_input(item)\n",
    "            response_text = f\"\\n\\n### Response:\\n{item['output']}\"\n",
    "\n",
    "            input_ids = tokenizer.encode(instruction_plus_input)\n",
    "            label_ids = tokenizer.encode(response_text)\n",
    "\n",
    "            self.inputs.append(input_ids)\n",
    "            self.labels.append(label_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "      return {\n",
    "            'input_ids': torch.tensor(self.inputs[index], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "oFrO6AQv4nCQ"
   },
   "source": [
    "# CUSTOM COLLATE FUNCTION IF NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "6c4541dd-051f-4e09-afa1-a9856d3b7201"
   },
   "outputs": [],
   "source": [
    "def collated_fromMLMtoCLM(labels,instr_len):\n",
    "    labels = labels[:,1:]\n",
    "    new_labels = torch.zeros((labels.size(0), labels.size(1) + 1), dtype=labels.dtype)\n",
    "    for i in range(0,len(labels)):\n",
    "        if len(labels[i,:])==0:\n",
    "            row_list=[end_of_text_token_id]\n",
    "\n",
    "        else:\n",
    "            if labels[i,-1]!=-100:\n",
    "                row_list = labels[i].tolist()\n",
    "                row_list.append(end_of_text_token_id)\n",
    "\n",
    "            else:\n",
    "                if (labels[i]==-100).all():\n",
    "                    row_list = labels[i].tolist()\n",
    "                    row_list.insert(0,end_of_text_token_id)\n",
    "                else:\n",
    "                    for j in range (len(labels[i,:])):\n",
    "                        if labels[i,j+1]==-100:\n",
    "                           row_list = labels[i].tolist()\n",
    "                           row_list.insert(j+1,end_of_text_token_id)\n",
    "                           break\n",
    "\n",
    "        new_labels[i] = torch.tensor(row_list, dtype=labels.dtype).to(device)\n",
    "        #new_labels[i,:instr_len[i]-1] = -100 #UNCOMMENT FOR INSTRUCTION MASKING IN LOSS FUNCTION\n",
    "\n",
    "    return new_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "d2f31e3e-b833-4127-a581-2151257e01aa",
    "outputId": "85594866-fd59-4adf-fb1a-1e1f8addbbbd"
   },
   "outputs": [],
   "source": [
    "def CLM_Collator(tokenized_data_input_tuple, tokenizer=GPT2Tokenizer.from_pretrained('gpt2',padding_side=\"right\", add_eos_token=True, add_bos_token=False)):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenized_data_input = [item[1] for item in tokenized_data_input_tuple]\n",
    "    instr_lengths = [item[0] for item in tokenized_data_input_tuple]\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "    collated_samples = data_collator(tokenized_data_input)\n",
    "    collated_samples['labels'] = collated_fromMLMtoCLM(collated_samples['labels'],instr_lengths)\n",
    "    return collated_samples\n",
    "\n",
    "# def CLM_Collator(tokenized_data_input, tokenizer=GPT2Tokenizer.from_pretrained('gpt2',padding_side=\"right\", add_eos_token=True, add_bos_token=False)):\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "#     data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "#     collated_samples=data_collator(tokenized_data_input)\n",
    "#     collated_samples['labels'] = collated_fromMLMtoCLM(collated_samples['labels'])\n",
    "#     return collated_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "c9tyZRNN4-4p"
   },
   "source": [
    "# TEST FUNCTIONS (DATASET-BATCHES-COLLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "cc655676-e87b-4f86-b2a3-895cdda3db67",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def check_input_label_shapes(train_loader):\n",
    "  for pairs in train_loader:\n",
    "      print(pairs['input_ids'].shape, pairs['labels'].shape)\n",
    "\n",
    "  print(pairs['input_ids'][0])\n",
    "  print(pairs['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "b4e43fa8-b6e7-4ddd-b497-186bbb55010f"
   },
   "outputs": [],
   "source": [
    "def collator_decoder_test(train_loader):\n",
    "  for j in train_loader:\n",
    "      tensor = j['input_ids'][0]\n",
    "      filtered_tensor = tensor[tensor != -100]\n",
    "      token_ids = filtered_tensor.tolist()\n",
    "      decoded_string = tokenizer.decode(token_ids, skip_special_tokens=False)\n",
    "      print(\"Decoded Input:\")\n",
    "      print(decoded_string)\n",
    "\n",
    "      tensor = j['labels'][0]\n",
    "      filtered_tensor = tensor[tensor != -100]\n",
    "      token_ids = filtered_tensor.tolist()\n",
    "      decoded_string = tokenizer.decode(token_ids, skip_special_tokens=False)\n",
    "      print(\"\\nDecode Label:\")\n",
    "      print(decoded_string)\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "cYhZs8Kh5Ifr"
   },
   "source": [
    "# DATA + TRAIN_TEST_VAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2ed4654-3a7b-466f-b109-8aceb586d630",
    "outputId": "4d2006f7-f02f-458f-ce60-b5febf132ad6"
   },
   "outputs": [],
   "source": [
    "data = download_data(dir+data_sub_dir+'/finaldataset_shortblocks.json')\n",
    "data = remove_extra_quotes(data)\n",
    "\n",
    "print(\"Number Of Samples:\",len(data),\"\\n\")\n",
    "print(\"Initial Sample Example:\\n\",data[400],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "6cbfcb1c-4136-41af-a17f-fcc954693d59"
   },
   "outputs": [],
   "source": [
    "train_data,test_data,val_data = train_test_val_split(data,0.9,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8347e123-6b24-4c07-8b56-33d4a7f93594",
    "outputId": "3f9a7283-815d-46c0-db50-9256bc4a11fc"
   },
   "outputs": [],
   "source": [
    "print(\"Training set length:\", len(train_data), \"//Validation set length:\", len(val_data),\"//Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "id": "vywDBymn56i1"
   },
   "source": [
    "# MODEL + TOKENIZER DOWNLOAD (RUN ONE CELL ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "8dkGiemDGZFM"
   },
   "source": [
    "## GPT2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "24aa7d40-c067-4f22-87a8-083f48fbfc04"
   },
   "outputs": [],
   "source": [
    "#BASE GPT2 MODEL FROM HUGGING FACE\n",
    "original_model_name=\"gpt2-medium\"\n",
    "model = GPT2LMHeadModel.from_pretrained(original_model_name)\n",
    "\n",
    "#TOKENIZER + COLLATOR\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "end_of_text_token_id = tokenizer.encode(\"<|endoftext|>\")[0]\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator_fn = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "id": "JuRbIjhX7lWD"
   },
   "outputs": [],
   "source": [
    "#SAVED GPT2 MODEL POST FINE-TUNING (IF EXISTS)\n",
    "original_model_name=\"gpt2-medium\"\n",
    "model_name=dir+sub_dir+'/final_model_'+original_model_name\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "end_of_text_token_id = tokenizer.encode(\"<|endoftext|>\")[0]\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator_fn = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "id": "1cEsoXWJUJOC"
   },
   "outputs": [],
   "source": [
    "def check_unknown_tokens(texts):\n",
    "    unknown_tokens = set()\n",
    "\n",
    "    tokens = tokenizer.encode(texts)\n",
    "    for token in tokens:\n",
    "        if token == 50256:\n",
    "            unknown_tokens.add(token)\n",
    "    return unknown_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "imPDd4sBUL5Y"
   },
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "  texts = str(train_data[10]['output'])\n",
    "  unknown_tokens = check_unknown_tokens(texts)\n",
    "  if len(unknown_tokens)!=0:\n",
    "    print(\"Unknown tokens:\", unknown_tokens)\n",
    "    print(train_data[10]['output'])\n",
    "    print(tokenizer.decode(tokenizer.encode(str(train_data[10]['output']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuhemMAdUNZO",
    "outputId": "f4d7c232-5759-441c-b451-69322ae5f52b"
   },
   "outputs": [],
   "source": [
    "#ADD NEW TOKENS\n",
    "new_token = [\"\"]\n",
    "num_added_toks = tokenizer.add_tokens(new_token)\n",
    "print(f\"Added {num_added_toks} new regular token.\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "TMl-JzKaGU23"
   },
   "source": [
    "## T5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "id": "YMGxUb8IWvWb"
   },
   "outputs": [],
   "source": [
    "#BASE T5 MODEL\n",
    "original_model_name = \"t5-base\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(original_model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(original_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator_fn = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "special_tokens_dict = {'additional_special_tokens': ['{', '}']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "id": "HXfCGakoYuDV"
   },
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dp4qd0VWxbw",
    "outputId": "44ea88a4-ec15-4f7d-deaa-da2bb34b53e2"
   },
   "outputs": [],
   "source": [
    "#SAVED T5 MODEL POST FINE-TUNING (IF EXISTS)\n",
    "original_model_name = \"t5-base\"\n",
    "model_name = dir+sub_dir+'/final_model_'+original_model_name\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator_fn = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "id": "GNoBWpKZsw6J"
   },
   "outputs": [],
   "source": [
    "#AWS MODEL\n",
    "original_model_name = \"t5-base\"\n",
    "model_name = dir+sub_dir+'/final_model_'+original_model_name+\"AWS\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator_fn = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvOfZgadzV-K",
    "outputId": "b6e9f146-3e9f-4fb8-9042-3b9c14670bf0"
   },
   "outputs": [],
   "source": [
    "#LoRA MODEL\n",
    "original_model_name = \"t5-base\"\n",
    "model_name = dir+sub_dir+'/final_model_'+original_model_name+\"LoRA\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator_fn = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "id": "KW0d2MbIQpUR"
   },
   "source": [
    "### CHECK IF T5 MODEL HAS ALL TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "id": "TfID_kS1I3ly"
   },
   "outputs": [],
   "source": [
    "def check_unknown_tokens(texts):\n",
    "    unknown_tokens = set()\n",
    "\n",
    "    tokens = tokenizer.encode(texts)\n",
    "    for token in tokens:\n",
    "        if token == 2:\n",
    "            unknown_tokens.add(token)\n",
    "    return unknown_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "id": "NNkISAFnJHcn"
   },
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "  texts = str(train_data[10]['output'])\n",
    "  unknown_tokens = check_unknown_tokens(texts)\n",
    "  if len(unknown_tokens)!=0:\n",
    "    print(\"Unknown tokens:\", unknown_tokens)\n",
    "    print(train_data[10]['output'])\n",
    "    print(tokenizer.decode(tokenizer.encode(str(train_data[10]['output']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnnQqUbEPw30",
    "outputId": "9bfa0380-906a-485d-83e6-94ed7df35caf"
   },
   "outputs": [],
   "source": [
    "#ADD NEW TOKENS\n",
    "new_tokens = [\"{\", \"}\"]\n",
    "num_added_tokens = tokenizer.add_tokens(new_tokens)\n",
    "print(f\"Added {num_added_tokens} new regular token.\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {
    "id": "3bDv6XIh1k-y"
   },
   "source": [
    "### T5 LoRA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "id": "XVi0AxPJ1j0z"
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "id": "qELfytst1xqg"
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "id": "OgiA9dnyR_Mz"
   },
   "source": [
    "## Load Model To Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufCJbSUWkDm8",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "0671822b-2c57-441f-df68-f0bf819ed99b"
   },
   "outputs": [],
   "source": [
    "print(f\"Num of param for {model_name}:\",sum(p.numel() for p in model.parameters()))\n",
    "print(f\"Max Length: {model.config.n_positions}\")\n",
    "model.to(device)  # Move the model to the appropriate device\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LelCz4TWozlN",
    "outputId": "0d35caf3-e2a8-4382-99ff-a681571215f8"
   },
   "outputs": [],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {
    "id": "wbd9s2JvHMys"
   },
   "source": [
    "### Model Size Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpD6lCMnHQWB",
    "outputId": "030e09a0-a068-4095-b97b-713af936307c"
   },
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    return size_all_mb\n",
    "\n",
    "original_model_size = get_model_size(model)\n",
    "print(original_model_size, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Eh_WSjHHnW7",
    "outputId": "c53e56ba-5a8b-4d5c-ad29-11ac11886f2e"
   },
   "outputs": [],
   "source": [
    "#reduce model to half ONLY FOR INFERENCE\n",
    "\n",
    "if device.type==\"cuda\":\n",
    "  model.half().to(device)\n",
    "\n",
    "def is_fp16(model):\n",
    "    for param in model.parameters():\n",
    "        if param.dtype != torch.float16:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "if is_fp16(model):\n",
    "    print(\"The model is in FP16 precision.\")\n",
    "else:\n",
    "    print(\"The model is not in FP16 precision.\")\n",
    "\n",
    "new_model_size = get_model_size(model)\n",
    "\n",
    "print(new_model_size, \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "id": "XcjR37Cw5bJL"
   },
   "source": [
    "# TOKENIZER + INSTRUCTION-DATASET + COLLATOR INITALIZATION FOR TRAINING\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "id": "bb959d67-704f-478c-b98a-685160ee8f11"
   },
   "outputs": [],
   "source": [
    "#TRAINING AND DATA SETTINGS\n",
    "\n",
    "#GPT2\n",
    "if \"gpt2\" in model_name:\n",
    "  num_workers = 0\n",
    "  batch_size = 8\n",
    "  epochs=9\n",
    "\n",
    "  torch.manual_seed(123)\n",
    "\n",
    "  train_dataset = InstructionDataset_GPT2(train_data, tokenizer)\n",
    "  val_dataset = InstructionDataset_GPT2(val_data, tokenizer)\n",
    "  test_dataset = InstructionDataset_GPT2(test_data, tokenizer)\n",
    "\n",
    "  #FOR TESTING PURPOSES:\n",
    "  train_loader = DataLoader(train_dataset,batch_size=batch_size,collate_fn=data_collator_fn,\n",
    "      shuffle=True,\n",
    "      drop_last=True,\n",
    "      num_workers=num_workers\n",
    "  )\n",
    "\n",
    "elif \"t5\" in model_name:\n",
    "  #T5\n",
    "  num_workers = 0\n",
    "  batch_size = 8\n",
    "  epochs=9\n",
    "\n",
    "  torch.manual_seed(123)\n",
    "\n",
    "  train_dataset = InstructionDataset_T5(train_data, tokenizer)\n",
    "  val_dataset = InstructionDataset_T5(val_data, tokenizer)\n",
    "  test_dataset = InstructionDataset_T5(test_data, tokenizer)\n",
    "\n",
    "  #FOR TESTING PURPOSES:\n",
    "  train_loader = DataLoader(train_dataset,batch_size=batch_size,collate_fn=data_collator_fn,\n",
    "      shuffle=True,\n",
    "      drop_last=True,\n",
    "      num_workers=num_workers\n",
    "  )\n",
    "\n",
    "else:\n",
    "  sys.exit(\"Error: model not defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "XrVopIbnX6fi",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "1ccf0cf1-3e07-4b5b-b0bd-865ecda3d41a"
   },
   "outputs": [],
   "source": [
    "check_input_label_shapes(train_loader)\n",
    "print('\\n\\n\\n')\n",
    "collator_decoder_test(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {
    "id": "pU8YfanMSrtv"
   },
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "id": "knWwDR646F-I"
   },
   "source": [
    "## TRAINING HYPERPARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "id": "nCZN35Ra63Hg"
   },
   "outputs": [],
   "source": [
    "if \"gpt2\" in original_model_name:\n",
    "  batch_size = 4\n",
    "  epochs=0.5\n",
    "  training_args = TrainingArguments(\n",
    "      output_dir=(dir+sub_dir+'results_'+original_model_name),\n",
    "      num_train_epochs=epochs,\n",
    "      per_device_train_batch_size=batch_size,\n",
    "      per_device_eval_batch_size=2*batch_size,\n",
    "      warmup_steps=int(0.1* epochs* (len(train_dataset)//batch_size)),\n",
    "      weight_decay=0.1,\n",
    "      logging_dir=dir+sub_dir+'logs_'+original_model_name,\n",
    "      logging_steps=100,\n",
    "      do_train=True,\n",
    "      do_eval=True,\n",
    "      eval_strategy=\"steps\",\n",
    "      eval_steps=int(len(train_dataset)/10),\n",
    "      save_strategy=\"steps\",\n",
    "      save_steps=2*int(len(train_dataset)/10),\n",
    "      save_total_limit=3,\n",
    "      load_best_model_at_end=True,\n",
    "      resume_from_checkpoint=True,\n",
    "      lr_scheduler_type='linear',\n",
    "      gradient_accumulation_steps=2,\n",
    "      max_grad_norm=1.0,\n",
    "      learning_rate=7.5e-5,\n",
    "  )\n",
    "\n",
    "  trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset= val_dataset,\n",
    "    data_collator=data_collator_fn,\n",
    "  )\n",
    "\n",
    "\n",
    "if \"t5\" in original_model_name:\n",
    "  batch_size = 8\n",
    "  epochs=15\n",
    "  fp16_bool=True\n",
    "  training_args = Seq2SeqTrainingArguments(\n",
    "      output_dir=(dir+sub_dir+'results_'+original_model_name),\n",
    "      num_train_epochs=epochs,\n",
    "      per_device_train_batch_size=batch_size,\n",
    "      per_device_eval_batch_size=2*batch_size,\n",
    "      warmup_steps=int(0.1* epochs* (len(train_dataset)//batch_size)),\n",
    "      weight_decay=0.1,\n",
    "      logging_dir=dir+sub_dir+'logs_'+original_model_name,\n",
    "      logging_steps=100,\n",
    "      do_train=True,\n",
    "      do_eval=True,\n",
    "      eval_strategy=\"steps\",\n",
    "      eval_steps=int(len(train_dataset)/10),\n",
    "      save_strategy=\"steps\",\n",
    "      save_steps=2*int(len(train_dataset)/10),\n",
    "      save_total_limit=3,\n",
    "      load_best_model_at_end=True,\n",
    "      resume_from_checkpoint=True,\n",
    "      lr_scheduler_type='linear',\n",
    "      gradient_accumulation_steps=2,\n",
    "      max_grad_norm=1.0,\n",
    "      learning_rate=9e-5,\n",
    "      remove_unused_columns=False,\n",
    "      fp16=fp16_bool\n",
    "  )\n",
    "\n",
    "  trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset= val_dataset,\n",
    "    data_collator=data_collator_fn,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {
    "id": "Yo6iA0LT6Yvb"
   },
   "source": [
    "## TRAINING + EVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {
    "id": "idFHJiPCNKqb"
   },
   "source": [
    "### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "id": "VwrB9M0DA2_w"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "rB8L4Bi8K4LZ",
    "outputId": "0d37ecf8-7470-4c7a-e87a-9ae94b4802fd"
   },
   "outputs": [],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {
    "id": "hMvzxeM5LB7L"
   },
   "source": [
    "### T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604
    },
    "id": "qJ6HTzWTLFTV",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5b97e5c7-1c56-45f1-f47b-be67f627ed83"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "3buaMckxLRqe",
    "outputId": "344b46fc-1854-44de-edb2-ac9ea50acd15"
   },
   "outputs": [],
   "source": [
    "trainer.evaluate(eval_dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {
    "id": "SyF4t5-R63v0"
   },
   "source": [
    "# SAVING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmQkA1InDiFb",
    "outputId": "f1395b61-cfb0-4d13-977e-fdf57cc08d11"
   },
   "outputs": [],
   "source": [
    "append_filename=\"LoRA\" #AWS or LoRA ETC\n",
    "filename = dir+sub_dir+'final_model_'+original_model_name+append_filename\n",
    "if os.path.exists(filename):\n",
    "    m=input(\"are you sure you want to overwrite file? reply with 'yes' or 'no'\")\n",
    "    if m.lower()=='yes':\n",
    "        model.save_pretrained(filename,safe_serialization=False)\n",
    "        tokenizer.save_pretrained(filename)\n",
    "\n",
    "else:\n",
    "    model.save_pretrained(filename,safe_serialization=False)\n",
    "    tokenizer.save_pretrained(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {
    "id": "40buTMXM6pUF"
   },
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {
    "id": "lTxpAMEnM5Lv"
   },
   "source": [
    "### GPT2 FINETUNED OUTPUT EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "gFgZ_PXcK4NO",
    "outputId": "3074df37-e287-446f-8c06-a88b2e76b647"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model_outputs=[]\n",
    "data_to_use = train_data[74:75]\n",
    "\n",
    "for i in tqdm(range(len(data_to_use))):\n",
    "  in_test = data_to_use[i]\n",
    "  sample_out = data_to_use[i]['output']\n",
    "  in_test=format_model_input(in_test)\n",
    "  input_ids = tokenizer.encode(in_test, return_tensors=\"pt\").to(device)\n",
    "  # output = model.generate(\n",
    "  #     input_ids=input_ids,\n",
    "  #     eos_token_id=50256,\n",
    "  #     max_length=len(input_ids) + 200,\n",
    "  #     num_return_sequences=1,\n",
    "  #     early_stopping=True,\n",
    "  #     pad_token_id=50256,\n",
    "  # )\n",
    "  output = model.generate(\n",
    "      input_ids=input_ids,\n",
    "      eos_token_id=50256,\n",
    "      max_length=len(input_ids) + 300,\n",
    "      num_beams=3,\n",
    "      num_return_sequences=1,\n",
    "      early_stopping=True,\n",
    "      pad_token_id=50256,\n",
    "      #repetition_penalty=1.5,  #TO EXPERIMENT WITH\n",
    "  )\n",
    "\n",
    "  decoded_output=tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "  stop_sequence = \"### Response\"\n",
    "  stop_index = decoded_output.find(stop_sequence, decoded_output.find(stop_sequence) + len(stop_sequence))\n",
    "  if stop_index != -1:\n",
    "      trimmed_output = decoded_output[:stop_index]\n",
    "  else:\n",
    "      trimmed_output = decoded_output\n",
    "\n",
    "  print('expected output:',sample_out,'model output:',trimmed_output,'\\n',sep='\\n')\n",
    "  model_outputs.append(trimmed_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {
    "id": "kqDacyDTM9-c"
   },
   "source": [
    "### T5 FINETUNED OUTPUT EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "id": "XdO8uOWSCaK7"
   },
   "outputs": [],
   "source": [
    "l=[{},{},{}]\n",
    "l[0]['input']='foam roll'\n",
    "l[1]['input']=\"warmup\"\n",
    "l[2]['input']='foam roll warmup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hs2eCJO_NIPx",
    "outputId": "76b08108-b2e0-4a52-e1e8-a00f2873a523"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model_outputs=[]\n",
    "data_to_use = l\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(len(data_to_use))):\n",
    "  in_test = data_to_use[i]\n",
    "  in_test=format_model_input(in_test)\n",
    "  #print(\"in_test:\\n\",in_test) #UNCOMMENT TO PRINT\n",
    "  input_ids = tokenizer.encode(in_test, return_tensors=\"pt\").to(device)\n",
    "\n",
    "  start_time = time.time()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        eos_token_id=1,\n",
    "        max_length= 400,\n",
    "        num_beams=2,\n",
    "        num_return_sequences=1,\n",
    "        early_stopping=True,\n",
    "        repetition_penalty=3.0,  #TO EXPERIMENT WITH\n",
    "    )\n",
    "  end_time = time.time()\n",
    "\n",
    "  decoded_output=tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "  stop_sequence = \"### Response\"\n",
    "  stop_index = decoded_output.find(stop_sequence, decoded_output.find(stop_sequence) + len(stop_sequence))\n",
    "  if stop_index != -1:\n",
    "      trimmed_output = decoded_output[:stop_index]\n",
    "  else:\n",
    "      trimmed_output = decoded_output\n",
    "\n",
    "  print('model output:',trimmed_output,'\\n',sep='\\n') #UNCOMMENT TO SEE OUTPUT\n",
    "  model_outputs.append(trimmed_output)\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "print(f\" model inference time: {inference_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {
    "id": "LGGIDI23-W9Q"
   },
   "source": [
    "### SAVE MODEL OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "id": "7-iqaARr-c70",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if len(model_outputs)==len(train_data):\n",
    "  output_file=dir+sub_dir+'final_model_'+original_model_name+'_model_outputs_train.json'\n",
    "\n",
    "elif data_to_use==test_data:\n",
    "  output_file=dir+sub_dir+'final_model_'+original_model_name+'_model_outputs_test.json'\n",
    "\n",
    "elif data_to_use==val_data:\n",
    "  output_file=dir+sub_dir+'final_model_'+original_model_name+'_model_outputs_val.json'\n",
    "\n",
    "else:\n",
    "  sys.exit(\"Error: lengths do not match with original dataset\")\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "  json.dump(model_outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {
    "id": "1wUnkOdGotz0"
   },
   "source": [
    "# TESTING + DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "id": "466xMbz5cC2H"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {
    "id": "2vpNvGxOwAh7"
   },
   "source": [
    "### TESTING + TRANSFORMATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "id": "wzQjPfMKb0GV"
   },
   "outputs": [],
   "source": [
    "def convert_output_to_list(model_outputs,model_name):\n",
    "  model_outputs_list=[]\n",
    "  if \"gpt2\" in model_name:\n",
    "    for i,generated in enumerate(model_outputs):\n",
    "      s = generated\n",
    "\n",
    "      start_index = s.find(\"### Response\")\n",
    "      if start_index != -1:\n",
    "        s = s[start_index:]\n",
    "\n",
    "      s = s.replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "      end_index = s.find(']}]') #POST PROCESSING\n",
    "      if end_index != -1:\n",
    "        s = s[:end_index + 3]\n",
    "\n",
    "      try:\n",
    "          s = ast.literal_eval(s)\n",
    "\n",
    "      except (ValueError, SyntaxError):\n",
    "          print(f\"ERROR: Output at index {i} is invalid and cannot be parsed.\")\n",
    "\n",
    "      if type(s) != list or not all(isinstance(item, dict) for item in s):\n",
    "        print(i,s,\"ERROR: not dict or not list\")\n",
    "\n",
    "      else:\n",
    "        model_outputs_list.append(s)\n",
    "\n",
    "\n",
    "  elif \"t5\" in model_name:\n",
    "    for i,generated in enumerate(model_outputs):\n",
    "      s = generated\n",
    "      s = s.replace(\"</s>\", \"\").strip()\n",
    "      s = s.strip(\"<pad> ### Response: \")\n",
    "\n",
    "      try:\n",
    "          s = ast.literal_eval(s)\n",
    "\n",
    "      except (ValueError, SyntaxError):  #POST PROCESSING\n",
    "        last_bracket_index = s.rfind('}')\n",
    "        if last_bracket_index != -1:\n",
    "            s = s[:last_bracket_index + 1]\n",
    "            s += ']'\n",
    "            try:\n",
    "                s=ast.literal_eval(s)\n",
    "            except (ValueError, SyntaxError):\n",
    "                print(f\"ERROR: Output at index {i} is invalid and cannot be parsed.\")\n",
    "\n",
    "      if type(s) != list or not all(isinstance(item, dict) for item in s):\n",
    "        print(i,s,\"ERROR: not dict or not list\")\n",
    "\n",
    "      else:\n",
    "        model_outputs_list.append(s)\n",
    "  else:\n",
    "    return \"ERROR: Get Model Name\"\n",
    "\n",
    "\n",
    "  print(f\"{len(model_outputs_list)} outputs converted correctly to list of dicts out of {len(model_outputs)} model outputs\")\n",
    "  return model_outputs_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "id": "xBRw6T6qfijT"
   },
   "outputs": [],
   "source": [
    "def check_parameters_correctness(model_outputs_list, param_list):\n",
    "    required_keys = {'exercise', 'sets'}\n",
    "    c=0\n",
    "    m=0\n",
    "    for i, outer_list in enumerate(model_outputs_list):\n",
    "        for j, dictionary in enumerate(outer_list):\n",
    "            m=m+1\n",
    "            if not required_keys.issubset(dictionary.keys()):\n",
    "                print(f\"ERROR: Dictionary at index [{i}][{j}] must have at least the keys {required_keys}.\")\n",
    "                c=c+1\n",
    "                continue\n",
    "\n",
    "            if not any(param in dictionary for param in param_list):\n",
    "                print(f\"ERROR: Dictionary at index [{i}][{j}] must have at least one of the keys from {param_list}.\")\n",
    "                c=c+1\n",
    "                continue\n",
    "\n",
    "            allowed_keys = required_keys.union(param_list)\n",
    "            if not set(dictionary.keys()).issubset(allowed_keys):\n",
    "                print(f\"ERROR: Dictionary at index [{i}][{j}] must only have keys from {allowed_keys}.\")\n",
    "                c=c+1\n",
    "                continue\n",
    "    print(f\"inconsistency in keys for {c} out of {m} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "id": "74OVAi4zl_oe"
   },
   "outputs": [],
   "source": [
    "def check_set_and_param_consistency(model_outputs_list,param_list): #MODIFY WHEN ADD PARMETERS OTHER THAN REPS (For ALL params other than exercise, #sets must be == len(param))\n",
    "  c=0\n",
    "  m=0\n",
    "  for i, outer_list in enumerate(model_outputs_list):\n",
    "      for j, dictionary in enumerate(outer_list):\n",
    "        sets = dictionary['sets']\n",
    "        for param in param_list:\n",
    "            m=m+1\n",
    "            if param in dictionary and sets != len(dictionary[param]):\n",
    "                c += 1\n",
    "                print(f\"ERROR: Dictionary at index [{i}][{j}] has #sets != len({param})\")\n",
    "\n",
    "  print(f\"inonsistency in sets and params for {c} out of {m} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "id": "N-bQ8P3ro0PV"
   },
   "outputs": [],
   "source": [
    "def no_consecutive_same_exercise(model_outputs_list):\n",
    "  c=0\n",
    "  for i, outer_list in enumerate(model_outputs_list):\n",
    "    k=1\n",
    "    for j in range(0,len(outer_list)-1):\n",
    "      if outer_list[j]['exercise']==outer_list[j+1]['exercise']:\n",
    "        if k==1:\n",
    "          print(f\"ERROR: Duplicated exercise at model output index {i}\")\n",
    "          c=c+1\n",
    "          k=0\n",
    "\n",
    "  print(f\"same exercise repeated consecutively for {c} out of {len(model_outputs_list)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "id": "Yzg32pIqEnn1"
   },
   "outputs": [],
   "source": [
    "def remove_consecutive_duplicates(model_outputs_list):\n",
    "    cleaned_outputs = []\n",
    "    for i, outer_list in enumerate(model_outputs_list):\n",
    "        new_list = []\n",
    "        for j in range(len(outer_list)):\n",
    "            if j == 0 or outer_list[j]['exercise'] != outer_list[j-1]['exercise']:\n",
    "                new_list.append(outer_list[j])\n",
    "        cleaned_outputs.append(new_list)\n",
    "    return cleaned_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "id": "o01hSAAP2vV7"
   },
   "outputs": [],
   "source": [
    "def count_param_frequency(model_outputs_list, param_list):\n",
    "    param_counts = {param: 0 for param in param_list}\n",
    "\n",
    "    for outer_list in model_outputs_list:\n",
    "        for param in param_list:\n",
    "            if any(param in dictionary for dictionary in outer_list):\n",
    "                param_counts[param] += 1\n",
    "\n",
    "    total_outer_lists = len(model_outputs_list)\n",
    "    param_percentages = {param: (count / total_outer_lists) * 100 for param, count in param_counts.items()}\n",
    "\n",
    "    return param_counts, param_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {
    "id": "d8LkoHpN78Gh"
   },
   "outputs": [],
   "source": [
    "def output_list_to_df(model_outputs_list,param_list):\n",
    "    flat_data = []\n",
    "    for i, outer_list in enumerate(model_outputs_list):\n",
    "        for d in outer_list:\n",
    "            row = [i, d['exercise'], d['sets']]\n",
    "            for param in param_list:\n",
    "                row.append(d.get(param, None))\n",
    "            flat_data.append(row)\n",
    "    columns = ['block', 'exercise', 'sets'] + param_list\n",
    "\n",
    "    df = pd.DataFrame(flat_data, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {
    "id": "FdajuCAjmT7U"
   },
   "source": [
    "### CHOOSE MODEL AND DATASET OUTPUTS. !!!!!!DO NOT RUN FIRST CELL IF YOU WANT THE VALUES FROM \"{MODEL}FINETUNED OUTPUT EXAMPLES\" EXECUTION!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {
    "id": "h9jvXwvSsmro"
   },
   "source": [
    "#### PARAM LIST: MODIFY IF NEW PARAMS ADDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "id": "-BGaOxHDsw5R"
   },
   "outputs": [],
   "source": [
    "param_list=['reps','time','distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {
    "id": "pJvuzbR_3M3X"
   },
   "source": [
    "#### SELECT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0bv4zDRllhy",
    "outputId": "a7eefdec-695b-4a47-c380-16c37b2fb5a5"
   },
   "outputs": [],
   "source": [
    "#MODEL OUTPUTS\n",
    "file_to_read = dir+sub_dir+'final_model_t5-base_model_outputs_train.json'\n",
    "with open(file_to_read, 'r') as f:\n",
    "    model_outputs = json.load(f)\n",
    "print(len(model_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "id": "OVeSoCl49u0V"
   },
   "outputs": [],
   "source": [
    "using_data=train_data\n",
    "data_outputs = [using_data[i]['output'] for i in range(len(using_data))]\n",
    "print(len(data_outputs))\n",
    "main_dataset_df = output_list_to_df(data_outputs,param_list)\n",
    "main_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {
    "id": "tK7YEbO66NgT"
   },
   "outputs": [],
   "source": [
    "model_outputs_list=[]\n",
    "for i in data:\n",
    "  model_outputs_list.append(i['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {
    "id": "1pQqd0QMb60S"
   },
   "source": [
    "### GPT2 RUN TESTS + TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bde84164-49a7-466c-a388-24b7797a1d54",
    "outputId": "5af8761f-8300-4b5c-c4e1-a49b3bc604ac"
   },
   "outputs": [],
   "source": [
    "model_outputs_list=convert_output_to_list(model_outputs,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2Ax1UlXg3zY",
    "outputId": "dbc6ba50-a0ec-486a-f6be-6bd123638860"
   },
   "outputs": [],
   "source": [
    "check_parameters_correctness(model_outputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pf2_D-t5g4wj",
    "outputId": "e5ec6fda-b3a2-4da0-fd26-98aa6249ca00"
   },
   "outputs": [],
   "source": [
    "check_set_and_param_consistency(model_outputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2iVBia_9hNat",
    "outputId": "0c946bb2-c908-4358-cdc2-b80dcc4bfd04"
   },
   "outputs": [],
   "source": [
    "no_consecutive_same_exercise(model_outputs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {
    "id": "DSg_c6AY4-qA"
   },
   "source": [
    "### GPT2 DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {
    "id": "FhMtuvC4C6R4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "h-UN45UJ5Fmi",
    "outputId": "323b03ab-43d5-406b-a033-851b936b9da5"
   },
   "outputs": [],
   "source": [
    "gpt2df=output_list_to_df(model_outputs_list)\n",
    "gpt2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVxwcIGi8TaF",
    "outputId": "7a951197-67d9-4b2e-b4de-99e0a9ffcc99"
   },
   "outputs": [],
   "source": [
    "#DATA ANALYSIS ON EXERCISES\n",
    "print(\"##############GPT2 OUTPUT##############\")\n",
    "total_number_of_ex = gpt2df['exercise'].count()\n",
    "max_number_of_ex_per_block = gpt2df.groupby('block')['exercise'].count().max()\n",
    "average_number_of_ex_per_outer_list = gpt2df.groupby('block')['exercise'].count().mean()\n",
    "median_number_of_ex_per_outer_list = gpt2df.groupby('block')['exercise'].count().median()\n",
    "std_dev_of_ex_per_outer_list = gpt2df.groupby('block')['exercise'].count().std()\n",
    "\n",
    "print(f\"Total number of exercises: {total_number_of_ex}\")\n",
    "print(f\"Max number of exercises per block: {max_number_of_ex_per_block}\")\n",
    "print(f\"Average number of exercises per block: {average_number_of_ex_per_outer_list}\")\n",
    "print(f\"Median number of exercises per block: {median_number_of_ex_per_outer_list}\")\n",
    "print(f\"Standard deviation of exercises per block: {std_dev_of_ex_per_outer_list}\")\n",
    "\n",
    "print(\"\\n##############TRAINING DATASET OUTPUT##############\")\n",
    "total_number_of_ex = main_dataset_df['exercise'].count()\n",
    "max_number_of_ex_per_block = main_dataset_df.groupby('block')['exercise'].count().max()\n",
    "average_number_of_ex_per_outer_list = main_dataset_df.groupby('block')['exercise'].count().mean()\n",
    "median_number_of_ex_per_outer_list = main_dataset_df.groupby('block')['exercise'].count().median()\n",
    "std_dev_of_ex_per_outer_list = main_dataset_df.groupby('block')['exercise'].count().std()\n",
    "\n",
    "print(f\"Total number of exercises: {total_number_of_ex}\")\n",
    "print(f\"Max number of exercises per block: {max_number_of_ex_per_block}\")\n",
    "print(f\"Average number of exercises per block: {average_number_of_ex_per_outer_list}\")\n",
    "print(f\"Median number of exercises per block: {median_number_of_ex_per_outer_list}\")\n",
    "print(f\"Standard deviation of exercises per block: {std_dev_of_ex_per_outer_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcCexY048abP",
    "outputId": "6256a0a7-3ac1-4c60-9184-2780915c6ba8"
   },
   "outputs": [],
   "source": [
    "#DATA ANALYSIS ON SETS\n",
    "print(\"##############GPT2 OUTPUT##############\")\n",
    "total_sets = gpt2df['sets'].sum()\n",
    "max_sets_per_block = gpt2df.groupby('block')['sets'].sum().max()\n",
    "average_sets_per_outer_list = gpt2df.groupby('block')['sets'].sum().mean()\n",
    "median_sets_per_outer_list = gpt2df.groupby('block')['sets'].sum().median()\n",
    "std_dev_sets_per_outer_list = gpt2df.groupby('block')['sets'].sum().std()\n",
    "\n",
    "print(f\"Total number of sets: {total_sets}\")\n",
    "print(f\"Max number of sets per block: {max_sets_per_block}\")\n",
    "print(f\"Average number of sets per block: {average_sets_per_outer_list}\")\n",
    "print(f\"Median number of sets per block: {median_sets_per_outer_list}\")\n",
    "print(f\"Standard deviation of sets per block: {std_dev_sets_per_outer_list}\")\n",
    "\n",
    "print(\"\\n##############TRAINING DATASET OUTPUT##############\")\n",
    "total_sets = main_dataset_df['sets'].sum()\n",
    "max_sets_per_block = main_dataset_df.groupby('block')['sets'].sum().max()\n",
    "average_sets_per_outer_list = main_dataset_df.groupby('block')['sets'].sum().mean()\n",
    "median_sets_per_outer_list = main_dataset_df.groupby('block')['sets'].sum().median()\n",
    "std_dev_sets_per_outer_list = main_dataset_df.groupby('block')['sets'].sum().std()\n",
    "\n",
    "print(f\"Total number of sets: {total_sets}\")\n",
    "print(f\"Max number of sets per block: {max_sets_per_block}\")\n",
    "print(f\"Average number of sets per block: {average_sets_per_outer_list}\")\n",
    "print(f\"Median number of sets per block: {median_sets_per_outer_list}\")\n",
    "print(f\"Standard deviation of sets per block: {std_dev_sets_per_outer_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSSeFvmw8dNo",
    "outputId": "274b86f7-3c1b-405a-cd4d-645f63ce9a07"
   },
   "outputs": [],
   "source": [
    "#DATA ANALYSIS ON REPS\n",
    "print(\"##############GPT2 OUTPUT##############\")\n",
    "gpt2df['max_reps'] = gpt2df['reps'].apply(lambda x: max(x) if x else 0)\n",
    "gpt2df['mean_reps'] = gpt2df['reps'].apply(lambda x: sum(x) / len(x) if x else 0)\n",
    "gpt2df['total_reps'] = gpt2df['reps'].apply(sum)\n",
    "\n",
    "mean_reps = gpt2df['mean_reps'].mean()\n",
    "median_reps = gpt2df['mean_reps'].median()\n",
    "total_reps = gpt2df['total_reps'].sum()\n",
    "max_reps_per_block = gpt2df.groupby('block')['total_reps'].sum().max()\n",
    "average_reps_per_outer_list = gpt2df.groupby('block')['total_reps'].sum().mean()\n",
    "median_reps_per_outer_list = gpt2df.groupby('block')['total_reps'].sum().median()\n",
    "std_dev_reps_per_outer_list = gpt2df.groupby('block')['total_reps'].sum().std()\n",
    "\n",
    "print(f\"Mean number of average number of reps per exercise: {mean_reps}\")\n",
    "print(f\"Median number of average number of reps per exercise: {median_reps}\")\n",
    "print(f\"Total number of reps: {total_reps}\")\n",
    "print(f\"Max number of reps per block: {max_reps_per_block}\")\n",
    "print(f\"Average number of reps per block: {average_reps_per_outer_list}\")\n",
    "print(f\"Median number of reps per block: {median_reps_per_outer_list}\")\n",
    "print(f\"Standard deviation of reps per block: {std_dev_reps_per_outer_list}\")\n",
    "\n",
    "print(\"\\n##############TRAINING DATASET OUTPUT##############\")\n",
    "\n",
    "main_dataset_df['max_reps'] = main_dataset_df['reps'].apply(lambda x: max(x) if x else 0)\n",
    "main_dataset_df['mean_reps'] = main_dataset_df['reps'].apply(lambda x: sum(x) / len(x) if x else 0)\n",
    "main_dataset_df['total_reps'] = main_dataset_df['reps'].apply(sum)\n",
    "\n",
    "mean_reps = main_dataset_df['mean_reps'].mean()\n",
    "median_reps = main_dataset_df['mean_reps'].median()\n",
    "total_reps = main_dataset_df['total_reps'].sum()\n",
    "max_reps_per_block = main_dataset_df.groupby('block')['total_reps'].sum().max()\n",
    "average_reps_per_outer_list = main_dataset_df.groupby('block')['total_reps'].sum().mean()\n",
    "median_reps_per_outer_list = main_dataset_df.groupby('block')['total_reps'].sum().median()\n",
    "std_dev_reps_per_outer_list = main_dataset_df.groupby('block')['total_reps'].sum().std()\n",
    "\n",
    "print(f\"Mean number of average number of reps per exercise: {mean_reps}\")\n",
    "print(f\"Median number of average number of reps per exercise: {median_reps}\")\n",
    "print(f\"Total number of reps: {total_reps}\")\n",
    "print(f\"Max number of reps per block: {max_reps_per_block}\")\n",
    "print(f\"Average number of reps per block: {average_reps_per_outer_list}\")\n",
    "print(f\"Median number of reps per block: {median_reps_per_outer_list}\")\n",
    "print(f\"Standard deviation of reps per block: {std_dev_reps_per_outer_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {
    "id": "zY3dt7Dl6etI"
   },
   "source": [
    "### T5 RUN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {
    "id": "Q28ylfXncYye"
   },
   "outputs": [],
   "source": [
    "model_name=\"t5-base\"\n",
    "model_outputs_list=convert_output_to_list(model_outputs,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKooWfqm6TB-",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "23207d01-bfb9-448a-96a5-c299c3bf98f3"
   },
   "outputs": [],
   "source": [
    "check_parameters_correctness(model_outputs_list,param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-tB_eRQ6UyM",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "442bf5c1-6df2-4aa8-a5c9-1e044ab05fc0"
   },
   "outputs": [],
   "source": [
    "check_set_and_param_consistency(model_outputs_list,param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTSo1PHA6Wym",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5a2a3456-f886-44e3-c6c2-99288a06dbb1"
   },
   "outputs": [],
   "source": [
    "no_consecutive_same_exercise(model_outputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {
    "id": "TmD3bW5BFbNZ"
   },
   "outputs": [],
   "source": [
    "model_outputs_list = remove_consecutive_duplicates(model_outputs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {
    "id": "0by45f6YwHSx"
   },
   "source": [
    "### T5 DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzp1Ca474oUG",
    "outputId": "9391fb0c-3e9d-48ec-a6ce-5e4e99a7a329"
   },
   "outputs": [],
   "source": [
    "param_counts, param_percentages = count_param_frequency(model_outputs_list, param_list)\n",
    "print(\"MODEL Parameter Counts:\", param_counts)\n",
    "print(\"MODEL Parameter Percentages:\", param_percentages)\n",
    "print()\n",
    "param_counts, param_percentages = count_param_frequency(data_outputs, param_list)\n",
    "print(\"DATASET Parameter Counts:\", param_counts)\n",
    "print(\"DATASET Parameter Percentages:\", param_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "lfGuyZU3s7iq",
    "outputId": "75781405-118d-4cff-b49e-2266dc81b9af"
   },
   "outputs": [],
   "source": [
    "t5df=output_list_to_df(model_outputs_list,param_list)\n",
    "t5df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9rTemcCu9gl",
    "outputId": "add4f6ef-eb4a-4589-ae87-ceb5d4a771ad"
   },
   "outputs": [],
   "source": [
    "#DATA ANALYSIS ON EXERCISES\n",
    "print(\"##############T5 OUTPUT##############\")\n",
    "total_number_of_ex = t5df['exercise'].count()\n",
    "max_number_of_ex_per_block = t5df.groupby('block')['exercise'].count().max()\n",
    "average_number_of_ex_per_outer_list = t5df.groupby('block')['exercise'].count().mean()\n",
    "median_number_of_ex_per_outer_list = t5df.groupby('block')['exercise'].count().median()\n",
    "std_dev_of_ex_per_outer_list = t5df.groupby('block')['exercise'].count().std()\n",
    "number_of_blocks_with_one_exercise = (main_dataset_df.groupby('block')['exercise'].count() == 1).sum()\n",
    "\n",
    "print(f\"Total number of exercises: {total_number_of_ex}\")\n",
    "print(f\"Max number of exercises per block: {max_number_of_ex_per_block}\")\n",
    "print(f\"Average number of exercises per block: {average_number_of_ex_per_outer_list}\")\n",
    "print(f\"Median number of exercises per block: {median_number_of_ex_per_outer_list}\")\n",
    "print(f\"Standard deviation of exercises per block: {std_dev_of_ex_per_outer_list}\")\n",
    "print(f\"Percentage of blocks with only one exercise: {number_of_blocks_with_one_exercise/len(model_outputs_list) *100}%\")\n",
    "\n",
    "print(\"\\n##############TRAINING DATASET OUTPUT##############\")\n",
    "total_number_of_ex = main_dataset_df['exercise'].count()\n",
    "max_number_of_ex_per_block = main_dataset_df.groupby('block')['exercise'].count().max()\n",
    "average_number_of_ex_per_outer_list = main_dataset_df.groupby('block')['exercise'].count().mean()\n",
    "median_number_of_ex_per_outer_list = main_dataset_df.groupby('block')['exercise'].count().median()\n",
    "std_dev_of_ex_per_outer_list = main_dataset_df.groupby('block')['exercise'].count().std()\n",
    "number_of_blocks_with_one_exercise = (main_dataset_df.groupby('block')['exercise'].count() == 1).sum()\n",
    "\n",
    "print(f\"Total number of exercises: {total_number_of_ex}\")\n",
    "print(f\"Max number of exercises per block: {max_number_of_ex_per_block}\")\n",
    "print(f\"Average number of exercises per block: {average_number_of_ex_per_outer_list}\")\n",
    "print(f\"Median number of exercises per block: {median_number_of_ex_per_outer_list}\")\n",
    "print(f\"Standard deviation of exercises per block: {std_dev_of_ex_per_outer_list}\")\n",
    "print(f\"Percentage of blocks with only one exercise: {number_of_blocks_with_one_exercise/len(model_outputs_list) *100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ob9w4RKLbs0t",
    "outputId": "6c0c8148-86fe-4a81-d6b2-781280babcb2"
   },
   "outputs": [],
   "source": [
    "#DATA ANALYSIS ON SETS\n",
    "print(\"##############T5 OUTPUT##############\")\n",
    "total_sets = t5df['sets'].sum()\n",
    "max_sets_per_block = t5df.groupby('block')['sets'].sum().max()\n",
    "average_sets_per_outer_list = t5df.groupby('block')['sets'].sum().mean()\n",
    "median_sets_per_outer_list = t5df.groupby('block')['sets'].sum().median()\n",
    "std_dev_sets_per_outer_list = t5df.groupby('block')['sets'].sum().std()\n",
    "\n",
    "print(f\"Total number of sets: {total_sets}\")\n",
    "print(f\"Max number of sets per block: {max_sets_per_block}\")\n",
    "print(f\"Average number of sets per block: {average_sets_per_outer_list}\")\n",
    "print(f\"Median number of sets per block: {median_sets_per_outer_list}\")\n",
    "print(f\"Standard deviation of sets per block: {std_dev_sets_per_outer_list}\")\n",
    "\n",
    "print(\"\\n##############TRAINING DATASET OUTPUT##############\")\n",
    "total_sets = main_dataset_df['sets'].sum()\n",
    "max_sets_per_block = main_dataset_df.groupby('block')['sets'].sum().max()\n",
    "average_sets_per_outer_list = main_dataset_df.groupby('block')['sets'].sum().mean()\n",
    "median_sets_per_outer_list = main_dataset_df.groupby('block')['sets'].sum().median()\n",
    "std_dev_sets_per_outer_list = main_dataset_df.groupby('block')['sets'].sum().std()\n",
    "\n",
    "print(f\"Total number of sets: {total_sets}\")\n",
    "print(f\"Max number of sets per block: {max_sets_per_block}\")\n",
    "print(f\"Average number of sets per block: {average_sets_per_outer_list}\")\n",
    "print(f\"Median number of sets per block: {median_sets_per_outer_list}\")\n",
    "print(f\"Standard deviation of sets per block: {std_dev_sets_per_outer_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "VJop4sOBxXAT",
    "outputId": "7bf2fcab-752f-4ee0-bba0-086912461b0d"
   },
   "outputs": [],
   "source": [
    "#DATA ANALYSIS ON REPS\n",
    "print(\"##############T5 OUTPUT##############\")\n",
    "t5df['max_reps'] = t5df['reps'].apply(lambda x: max(x) if x else 0)\n",
    "t5df['mean_reps'] = t5df['reps'].apply(lambda x: sum(x) / len(x) if x else 0)\n",
    "t5df['total_reps'] = t5df['reps'].apply(sum)\n",
    "\n",
    "mean_reps = t5df['mean_reps'].mean()\n",
    "median_reps = t5df['mean_reps'].median()\n",
    "total_reps = t5df['total_reps'].sum()\n",
    "max_reps_per_block = t5df.groupby('block')['total_reps'].sum().max()\n",
    "average_reps_per_outer_list = t5df.groupby('block')['total_reps'].sum().mean()\n",
    "median_reps_per_outer_list = t5df.groupby('block')['total_reps'].sum().median()\n",
    "std_dev_reps_per_outer_list = t5df.groupby('block')['total_reps'].sum().std()\n",
    "\n",
    "print(f\"Mean number of average number of reps per exercise: {mean_reps}\")\n",
    "print(f\"Median number of average number of reps per exercise: {median_reps}\")\n",
    "print(f\"Total number of reps: {total_reps}\")\n",
    "print(f\"Max number of reps per block: {max_reps_per_block}\")\n",
    "print(f\"Average number of reps per block: {average_reps_per_outer_list}\")\n",
    "print(f\"Median number of reps per block: {median_reps_per_outer_list}\")\n",
    "print(f\"Standard deviation of reps per block: {std_dev_reps_per_outer_list}\")\n",
    "\n",
    "print(\"\\n##############TRAINING DATASET OUTPUT##############\")\n",
    "\n",
    "main_dataset_df['max_reps'] = main_dataset_df['reps'].apply(lambda x: max(x) if x else 0)\n",
    "main_dataset_df['mean_reps'] = main_dataset_df['reps'].apply(lambda x: sum(x) / len(x) if x else 0)\n",
    "main_dataset_df['total_reps'] = main_dataset_df['reps'].apply(sum)\n",
    "\n",
    "mean_reps = main_dataset_df['mean_reps'].mean()\n",
    "median_reps = main_dataset_df['mean_reps'].median()\n",
    "total_reps = main_dataset_df['total_reps'].sum()\n",
    "max_reps_per_block = main_dataset_df.groupby('block')['total_reps'].sum().max()\n",
    "average_reps_per_outer_list = main_dataset_df.groupby('block')['total_reps'].sum().mean()\n",
    "median_reps_per_outer_list = main_dataset_df.groupby('block')['total_reps'].sum().median()\n",
    "std_dev_reps_per_outer_list = main_dataset_df.groupby('block')['total_reps'].sum().std()\n",
    "\n",
    "print(f\"Mean number of average number of reps per exercise: {mean_reps}\")\n",
    "print(f\"Median number of average number of reps per exercise: {median_reps}\")\n",
    "print(f\"Total number of reps: {total_reps}\")\n",
    "print(f\"Max number of reps per block: {max_reps_per_block}\")\n",
    "print(f\"Average number of reps per block: {average_reps_per_outer_list}\")\n",
    "print(f\"Median number of reps per block: {median_reps_per_outer_list}\")\n",
    "print(f\"Standard deviation of reps per block: {std_dev_reps_per_outer_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {
    "id": "y2rq9BjHozUK"
   },
   "source": [
    "# EVALUATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHoSJhRipDg3",
    "outputId": "2c743d68-5d10-4a23-ef17-08cabf5f8348"
   },
   "outputs": [],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {
    "id": "YXRpH1slo3vS"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {
    "id": "kqhE7DfZzSoI"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {
    "id": "_xZoogz8o_I8"
   },
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, hypothesis):\n",
    "    reference_tokens = [nltk.word_tokenize(reference)]\n",
    "    hypothesis_tokens = nltk.word_tokenize(hypothesis)\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return sentence_bleu(reference_tokens, hypothesis_tokens, smoothing_function=smoothie)\n",
    "\n",
    "def calculate_rouge(reference, hypothesis):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    return scorer.score(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {
    "id": "LlsYrc38Gpla"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kO99PnpNzVvn",
    "outputId": "1e0afb83-9ce2-4a07-bf55-36848772f499"
   },
   "outputs": [],
   "source": [
    "reference_texts = [str(i['output']) for i in train_data]\n",
    "print(len(reference_texts), len(model_outputs))\n",
    "for i in range(len(model_outputs)):\n",
    "  model_outputs[i]=model_outputs[i].strip(\"<pad> ### Response: \")\n",
    "  model_outputs[i]=model_outputs[i].replace(\" { \", \"{\").replace(\" }\", \"}\").replace(\",\",\", \").replace(\"} \",\"}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WnxRLhVX-yzb",
    "outputId": "036083d0-c1ea-4147-a356-ddd9e5b534df"
   },
   "outputs": [],
   "source": [
    "bleu_scores = []\n",
    "rouge1_scores = []\n",
    "rouge2_scores = []\n",
    "rougeL_scores = []\n",
    "\n",
    "for ref, gen in zip(reference_texts, model_outputs):\n",
    "\n",
    "    bleu_score = calculate_bleu(ref, gen)\n",
    "    rouge_scores = calculate_rouge(ref, gen)\n",
    "\n",
    "    bleu_scores.append(bleu_score)\n",
    "    rouge1_scores.append(rouge_scores['rouge1'].fmeasure)\n",
    "    rouge2_scores.append(rouge_scores['rouge2'].fmeasure)\n",
    "    rougeL_scores.append(rouge_scores['rougeL'].fmeasure)\n",
    "\n",
    "\n",
    "\n",
    "bleu_mean = np.mean(bleu_scores)\n",
    "bleu_std = np.std(bleu_scores)\n",
    "\n",
    "rouge1_mean = np.mean(rouge1_scores)\n",
    "rouge1_std = np.std(rouge1_scores)\n",
    "\n",
    "rouge2_mean = np.mean(rouge2_scores)\n",
    "rouge2_std = np.std(rouge2_scores)\n",
    "\n",
    "rougeL_mean = np.mean(rougeL_scores)\n",
    "rougeL_std = np.std(rougeL_scores)\n",
    "\n",
    "print(f\"Average BLEU Score: {bleu_mean:.4f} ± {bleu_std:.4f}\")\n",
    "print(f\"Average ROUGE-1 F1 Score: {rouge1_mean:.4f} ± {rouge1_std:.4f}\")\n",
    "print(f\"Average ROUGE-2 F1 Score: {rouge2_mean:.4f} ± {rouge2_std:.4f}\")\n",
    "print(f\"Average ROUGE-L F1 Score: {rougeL_mean:.4f} ± {rougeL_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01M_Div37HRM",
    "outputId": "a3dd4c71-deb5-4137-fa80-0aa3e8855c4f"
   },
   "outputs": [],
   "source": [
    "c=0\n",
    "d=0\n",
    "for i in model_outputs_list:\n",
    "  d=d+1\n",
    "  sets=i[0]['sets']\n",
    "  exo=i[0]['exercise']\n",
    "  for j in i:\n",
    "    if j['exercise']==exo and j['sets']!=sets:\n",
    "      print(i,'\\n')\n",
    "      c=c+1\n",
    "      break\n",
    "print(c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {
    "id": "ld6XvSXzvEzr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QnAvtTLw5hRq",
    "Nz0O_NSx4Z5q",
    "oFrO6AQv4nCQ",
    "c9tyZRNN4-4p",
    "cYhZs8Kh5Ifr",
    "8dkGiemDGZFM",
    "TMl-JzKaGU23",
    "3bDv6XIh1k-y",
    "OgiA9dnyR_Mz",
    "XcjR37Cw5bJL",
    "pU8YfanMSrtv",
    "knWwDR646F-I",
    "idFHJiPCNKqb",
    "SyF4t5-R63v0",
    "40buTMXM6pUF",
    "lTxpAMEnM5Lv",
    "1wUnkOdGotz0",
    "2vpNvGxOwAh7",
    "h9jvXwvSsmro",
    "pJvuzbR_3M3X",
    "1pQqd0QMb60S",
    "DSg_c6AY4-qA",
    "zY3dt7Dl6etI",
    "0by45f6YwHSx",
    "y2rq9BjHozUK",
    "kqhE7DfZzSoI",
    "LlsYrc38Gpla"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
