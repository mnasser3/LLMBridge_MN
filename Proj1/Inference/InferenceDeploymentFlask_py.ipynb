{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2MdemTLWnh3F",
    "outputId": "63da5e91-b5b2-44cf-da08-60a99457a716"
   },
   "outputs": [],
   "source": [
    "!ngrok authtoken ENTER INFO HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2-XMZhcGPDaF",
    "outputId": "f7d9c9bc-33c4-42be-c963-0e5b9d2d3821"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aGhaJ9KEQCqM",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "427a8bbb-e42f-42ad-ee58-dec209c4df37"
   },
   "outputs": [],
   "source": [
    "!pip install Flask\n",
    "# !pip install flask-ngrok\n",
    "# !pip install flask-ngrok pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13zntlYXBzDM",
    "outputId": "7fcc09b5-6e9b-4125-c7ce-627bbc3e946c"
   },
   "outputs": [],
   "source": [
    "!npm install -g localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MqmxtdBRCQ3B",
    "outputId": "5c4dfe04-794f-4f85-c2f3-fc3be7eccfe8"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Function to start localtunnel and get the URL\n",
    "def start_localtunnel():\n",
    "    process = subprocess.Popen(['lt', '--port', '5000'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    for _ in range(10):  # Try for a certain number of lines\n",
    "        output = process.stdout.readline().decode('utf-8')\n",
    "        url_match = re.search(r'http[s]?://[^\\s]+', output)\n",
    "        if url_match:\n",
    "            return url_match.group(0)\n",
    "        time.sleep(1)  # Wait a bit before reading the next line\n",
    "\n",
    "    process.terminate()\n",
    "    raise Exception(\"Failed to get the public URL from localtunnel.\")\n",
    "\n",
    "# Start localtunnel and get the URL\n",
    "public_url = start_localtunnel()\n",
    "print(f'Public URL: {public_url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCb-B9fgQA3n",
    "outputId": "83d1381e-c602-413f-d02e-5f91e913e460"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "# from flask_ngrok import run_with_ngrok\n",
    "# from pyngrok import ngrok\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import ast\n",
    "import re\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "dir=\"/content/drive/MyDrive/BridgeAthletics/Training/AdvancedData2\"\n",
    "original_model_name = \"t5-base\"\n",
    "model_name = dir+'/final_model_'+original_model_name\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "if device.type==\"cuda\":\n",
    "  model.half().to(device)\n",
    "model.eval()\n",
    "\n",
    "def str_to_list(generated):\n",
    "    s = generated\n",
    "    s = s.replace(\"</s>\", \"\").strip()\n",
    "    s = s.strip(\"<pad>\")\n",
    "    s = s.strip(\" ### Response: \")\n",
    "    try:\n",
    "        s = ast.literal_eval(s)\n",
    "    except (ValueError, SyntaxError):  #POST PROCESSING\n",
    "      last_bracket_index = s.rfind('}')\n",
    "      if last_bracket_index != -1:\n",
    "          s = s[:last_bracket_index + 1]\n",
    "          s += ']'\n",
    "          try:\n",
    "              s=ast.literal_eval(s)\n",
    "          except (ValueError, SyntaxError):\n",
    "              return -1\n",
    "    if type(s) != list or not all(isinstance(item, dict) for item in s):\n",
    "      return -1\n",
    "    else:\n",
    "      return s\n",
    "\n",
    "def check_parameters_correctness(model_output_list, param_list=['reps','time','distance']):\n",
    "    required_keys = {'exercise', 'sets'}\n",
    "    for dictionary in (model_output_list):\n",
    "        if not required_keys.issubset(dictionary.keys()):\n",
    "            return -2\n",
    "\n",
    "        allowed_keys = required_keys.union(param_list)\n",
    "        if not set(dictionary.keys()).issubset(allowed_keys):\n",
    "          return -3\n",
    "    return 1\n",
    "\n",
    "def get_set_and_param_consistency(model_output_list,param_list=['reps','time','distance']):\n",
    "  required_keys = {'exercise', 'sets'}\n",
    "  for d in range(len(model_output_list)):\n",
    "    sets = model_output_list[d]['sets']\n",
    "    if sets == 0:\n",
    "      return -1\n",
    "    for param in param_list:\n",
    "      if param in model_output_list[d]:\n",
    "        param_len = len(model_output_list[d][param])\n",
    "        if sets > param_len:\n",
    "            last_value = model_output_list[d][param][-1]\n",
    "            model_output_list[d][param].extend([last_value] * (sets - param_len))\n",
    "        elif sets < param_len:\n",
    "            model_output_list[d][param] = model_output_list[d][param][:sets]\n",
    "  return model_output_list\n",
    "\n",
    "def remove_consecutive_duplicates(model_outputs_list):\n",
    "    cleaned_output = []\n",
    "    for j in range(len(model_outputs_list)):\n",
    "      if j == 0 or model_outputs_list[j]['exercise'] != model_outputs_list[j-1]['exercise']:\n",
    "        cleaned_output.append(model_outputs_list[j])\n",
    "    return cleaned_output\n",
    "\n",
    "\n",
    "def format_model_input(text):\n",
    "  def normalize_userinput(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[:/\\\\.]', ',', text)\n",
    "    text = re.sub(r'\\-', '', text)\n",
    "    text = re.sub(r'\\+', 'and', text)\n",
    "    text = re.sub(r'\\&', 'and', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'\\s*,\\s*', ', ', text)\n",
    "    if ((text.startswith(\"'\") and text.endswith(\"'\")) or (text.startswith('\"') and text.endswith('\"'))):\n",
    "      text=text[1:-1]\n",
    "    return text\n",
    "  instruction = f\"### Instruction:\\nGenerate a workout block in JSON format for the following block title.\"\n",
    "  normalized_input = normalize_userinput(text)\n",
    "  input_text = f\"\\n\\n### Input:\\n{normalized_input}\"\n",
    "  return instruction + input_text\n",
    "\n",
    "app = Flask(__name__)\n",
    "# run_with_ngrok(app)\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    print(\"Running\")\n",
    "    try:\n",
    "        data = request.get_json(force=True)\n",
    "        input_text = data['input_text']\n",
    "        input_text = format_model_input(input_text)\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                eos_token_id=1,\n",
    "                max_length=400,\n",
    "                num_beams=2,\n",
    "                num_return_sequences=1,\n",
    "                early_stopping=True,\n",
    "                repetition_penalty=3.0,\n",
    "                do_sample=True,\n",
    "                top_k=9,\n",
    "                top_p=0.93,\n",
    "                temperature=1.2,\n",
    "            )\n",
    "\n",
    "        decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        stop_sequence = \"### Response\"\n",
    "        stop_index = decoded_output.find(stop_sequence, decoded_output.find(stop_sequence) + len(stop_sequence))\n",
    "        if stop_index != -1:\n",
    "            output = decoded_output[:stop_index]\n",
    "        else:\n",
    "            output = decoded_output\n",
    "\n",
    "        output_list = str_to_list(output)\n",
    "        if output_list == -1:\n",
    "            return jsonify({'output_text': f\"Error in output {output}\"})\n",
    "\n",
    "        if check_parameters_correctness(output_list) != 1:\n",
    "            return jsonify({'output_text': f\"Error in output {output}\"})\n",
    "\n",
    "        output_list = get_set_and_param_consistency(output_list)\n",
    "        if output_list == -1:\n",
    "            return jsonify({'output_text': f\"Error in output {output}\"})\n",
    "\n",
    "        output_list = remove_consecutive_duplicates(output_list)\n",
    "\n",
    "        return jsonify({'output_text': output_list})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)})\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # public_url = ngrok.connect(5000)\n",
    "  # print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:5000\\\"\".format(public_url))\n",
    "  app.run(port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzE0HGqYpGOv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDOZ0ZAFpGMq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UYAbW_-pGKD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtrNcy9bpGH-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9Fzzi2ppGFY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmAJbn4IpGDj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InDfsC-9pGAt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QbNdjObWpF20"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErjSQz4tpHJV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pIFAFKY_pHHQ",
    "outputId": "b555c873-f7b8-4121-b943-3678376359fd"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "# from flask_ngrok import run_with_ngrok\n",
    "# from pyngrok import ngrok\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import ast\n",
    "import re\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "dir=\"/content/drive/MyDrive/BridgeAthletics/Training/AdvancedData2\"\n",
    "original_model_name = \"t5-base\"\n",
    "model_name = dir+'/final_model_'+original_model_name+\"AWS\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "if device.type==\"cuda\":\n",
    "  model.half().to(device)\n",
    "model.eval()\n",
    "\n",
    "def str_to_list(generated):\n",
    "    s = generated\n",
    "    s = s.replace(\"</s>\", \"\").strip()\n",
    "    s = s.strip(\"<pad>\")\n",
    "    s = s.strip(\" ### Response: \")\n",
    "    try:\n",
    "        s = ast.literal_eval(s)\n",
    "    except (ValueError, SyntaxError):  #POST PROCESSING\n",
    "      last_bracket_index = s.rfind('}')\n",
    "      if last_bracket_index != -1:\n",
    "          s = s[:last_bracket_index + 1]\n",
    "          s += ']'\n",
    "          try:\n",
    "              s=ast.literal_eval(s)\n",
    "          except (ValueError, SyntaxError):\n",
    "              return -1\n",
    "    if type(s) != list or not all(isinstance(item, dict) for item in s):\n",
    "      return -1\n",
    "    else:\n",
    "      return s\n",
    "\n",
    "def check_parameters_correctness(model_output_list, param_list=['reps','time','distance']):\n",
    "    required_keys = {'exercise', 'sets'}\n",
    "    for dictionary in (model_output_list):\n",
    "        if not required_keys.issubset(dictionary.keys()):\n",
    "            return -2\n",
    "\n",
    "        allowed_keys = required_keys.union(param_list)\n",
    "        if not set(dictionary.keys()).issubset(allowed_keys):\n",
    "          return -3\n",
    "    return 1\n",
    "\n",
    "def get_set_and_param_consistency(model_output_list,param_list=['reps','time','distance']):\n",
    "  required_keys = {'exercise', 'sets'}\n",
    "  for d in range(len(model_output_list)):\n",
    "    sets = model_output_list[d]['sets']\n",
    "    if sets == 0:\n",
    "      return -1\n",
    "    for param in param_list:\n",
    "      if param in model_output_list[d]:\n",
    "        param_len = len(model_output_list[d][param])\n",
    "        if sets > param_len:\n",
    "            last_value = model_output_list[d][param][-1]\n",
    "            model_output_list[d][param].extend([last_value] * (sets - param_len))\n",
    "        elif sets < param_len:\n",
    "            model_output_list[d][param] = model_output_list[d][param][:sets]\n",
    "  return model_output_list\n",
    "\n",
    "def remove_consecutive_duplicates(model_outputs_list):\n",
    "    cleaned_output = []\n",
    "    for j in range(len(model_outputs_list)):\n",
    "      if j == 0 or model_outputs_list[j]['exercise'] != model_outputs_list[j-1]['exercise']:\n",
    "        cleaned_output.append(model_outputs_list[j])\n",
    "    return cleaned_output\n",
    "\n",
    "\n",
    "def format_model_input(text):\n",
    "  def normalize_userinput(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[:/\\\\.]', ',', text)\n",
    "    text = re.sub(r'\\-', '', text)\n",
    "    text = re.sub(r'\\+', 'and', text)\n",
    "    text = re.sub(r'\\&', 'and', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'\\s*,\\s*', ', ', text)\n",
    "    if ((text.startswith(\"'\") and text.endswith(\"'\")) or (text.startswith('\"') and text.endswith('\"'))):\n",
    "      text=text[1:-1]\n",
    "    return text\n",
    "  instruction = f\"### Instruction:\\nGenerate a workout block in JSON format for the following block title.\"\n",
    "  normalized_input = normalize_userinput(text)\n",
    "  input_text = f\"\\n\\n### Input:\\n{normalized_input}\"\n",
    "  return instruction + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zt_Xr8DsprLX"
   },
   "outputs": [],
   "source": [
    "def predict(input_text):\n",
    "  input_text = format_model_input(input_text)\n",
    "  input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "      output = model.generate(\n",
    "          input_ids=input_ids,\n",
    "          eos_token_id=1,\n",
    "          max_length=400,\n",
    "          num_beams=2,\n",
    "          num_return_sequences=1,\n",
    "          early_stopping=True,\n",
    "          repetition_penalty=3.0,\n",
    "          do_sample=True,\n",
    "          top_k=9,\n",
    "          top_p=0.96,\n",
    "          temperature=1.2,\n",
    "      )\n",
    "\n",
    "  decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "  stop_sequence = \"### Response\"\n",
    "  stop_index = decoded_output.find(stop_sequence, decoded_output.find(stop_sequence) + len(stop_sequence))\n",
    "  if stop_index != -1:\n",
    "      output = decoded_output[:stop_index]\n",
    "  else:\n",
    "      output = decoded_output\n",
    "\n",
    "  output_list = str_to_list(output)\n",
    "  if output_list == -1:\n",
    "      return f\"Error in output {output}\"\n",
    "\n",
    "  if check_parameters_correctness(output_list) != 1:\n",
    "      return f\"Error in output {output}\"\n",
    "\n",
    "  output_list = get_set_and_param_consistency(output_list)\n",
    "  if output_list == -1:\n",
    "      return f\"Error in output {output}\"\n",
    "\n",
    "  output_list = remove_consecutive_duplicates(output_list)\n",
    "\n",
    "  return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGyEWgVQpHEp",
    "outputId": "eb67af40-b54a-4423-c110-0832fb99b6e0"
   },
   "outputs": [],
   "source": [
    "predict(\"arms\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
