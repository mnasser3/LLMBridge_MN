{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "h1TBE7xXn8Sb"
   },
   "source": [
    "# GENERAL LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QsSsEauaLN5",
    "outputId": "2e5132f3-a37e-46e2-b42b-dcecebd187b2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orttIbDvbUX0",
    "outputId": "3509b640-5175-494f-cb81-50df2d24fda3"
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install transformers[torch]\n",
    "!pip install transformers peft\n",
    "\n",
    "# !pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "UTv_rzjtNMPD"
   },
   "outputs": [],
   "source": [
    "# NEEDS TO BE PARENT DIRECTORY OF TRAINING\n",
    "dir= '/content/drive/MyDrive/BridgeAthletics/Proj2'\n",
    "sub_dir='/TrainingProj2/'\n",
    "data_sub_dir='/Data2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "1f8126f0-f17b-4523-b604-224100cd72ab"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import torch\n",
    "#import accelerate\n",
    "#from accelerate import Accelerator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "sys.path.append(dir)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from peft import get_peft_model, LoraConfig, LoraModel\n",
    "\n",
    "#CUSTOM FUNCTIONS FROM FUNCTIONS.PY\n",
    "from TrainingProj2.Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "27b89d49-10f7-4bac-8d40-c87fd4a03306"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, Seq2SeqTrainer, Seq2SeqTrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfYVE42a3m6B",
    "outputId": "471e21da-74e3-4e8e-a7a2-e786975d6647"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "QnAvtTLw5hRq"
   },
   "source": [
    "# MODEL + TOKENIZER LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "af896bc7-7749-457a-b385-d0a8da1622d4"
   },
   "outputs": [],
   "source": [
    "#MODEL SELECTION: GPT2\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "TiL9xSQTLdXb"
   },
   "outputs": [],
   "source": [
    "#MODEL SELECTION: T5\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq, BitsAndBytesConfig, LongT5ForConditionalGeneration, AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "Nz0O_NSx4Z5q"
   },
   "source": [
    "# DATASET CLASS - FORMATTING + PREPARING FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "958ed0fb-2c2b-4c2a-a5a3-6eacf4ea4e64"
   },
   "outputs": [],
   "source": [
    "class InstructionDataset_GPT2(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        self.instruction_lengths = []\n",
    "        for item in data:\n",
    "            instruction_plus_input = format_model_input(item)\n",
    "            response_text = f\"\\n\\n### Response:\\n{item['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "            instruction_length = len(tokenizer.encode(instruction_plus_input))\n",
    "            self.instruction_lengths.append(instruction_length)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # return self.instruction_lengths[index], self.encoded_texts[index] #(TO USE WITH CUSTOM COLLATE)\n",
    "        return self.encoded_texts[index] #(TO USE WITH TRANSFORMERS COLLATE)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class InstructionDataset_T5(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.inputs=[]\n",
    "        self.labels=[]\n",
    "        for item in data:\n",
    "            instruction_plus_input = format_model_input(item)\n",
    "            response_text = f\"### Response:\\n{item['output']}\"\n",
    "\n",
    "            input_ids = tokenizer.encode(instruction_plus_input)\n",
    "            label_ids = tokenizer.encode(response_text)\n",
    "\n",
    "            self.inputs.append(input_ids)\n",
    "            self.labels.append(label_ids)\n",
    "\n",
    "        self.inputs = np.array([np.array(x) for x in self.inputs], dtype=object)\n",
    "        self.labels = np.array([np.array(x) for x in self.labels], dtype=object)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "      return {\n",
    "            'input_ids': torch.tensor(self.inputs[index], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "oFrO6AQv4nCQ"
   },
   "source": [
    "# CUSTOM COLLATE FUNCTION IF NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "6c4541dd-051f-4e09-afa1-a9856d3b7201"
   },
   "outputs": [],
   "source": [
    "def collated_fromMLMtoCLM(labels,instr_len):\n",
    "    labels = labels[:,1:]\n",
    "    new_labels = torch.zeros((labels.size(0), labels.size(1) + 1), dtype=labels.dtype)\n",
    "    for i in range(0,len(labels)):\n",
    "        if len(labels[i,:])==0:\n",
    "            row_list=[end_of_text_token_id]\n",
    "\n",
    "        else:\n",
    "            if labels[i,-1]!=-100:\n",
    "                row_list = labels[i].tolist()\n",
    "                row_list.append(end_of_text_token_id)\n",
    "\n",
    "            else:\n",
    "                if (labels[i]==-100).all():\n",
    "                    row_list = labels[i].tolist()\n",
    "                    row_list.insert(0,end_of_text_token_id)\n",
    "                else:\n",
    "                    for j in range (len(labels[i,:])):\n",
    "                        if labels[i,j+1]==-100:\n",
    "                           row_list = labels[i].tolist()\n",
    "                           row_list.insert(j+1,end_of_text_token_id)\n",
    "                           break\n",
    "\n",
    "        new_labels[i] = torch.tensor(row_list, dtype=labels.dtype).to(device)\n",
    "        #new_labels[i,:instr_len[i]-1] = -100 #UNCOMMENT FOR INSTRUCTION MASKING IN LOSS FUNCTION\n",
    "\n",
    "    return new_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "d2f31e3e-b833-4127-a581-2151257e01aa",
    "outputId": "85594866-fd59-4adf-fb1a-1e1f8addbbbd"
   },
   "outputs": [],
   "source": [
    "def CLM_Collator(tokenized_data_input_tuple, tokenizer=GPT2Tokenizer.from_pretrained('gpt2',padding_side=\"right\", add_eos_token=True, add_bos_token=False)):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenized_data_input = [item[1] for item in tokenized_data_input_tuple]\n",
    "    instr_lengths = [item[0] for item in tokenized_data_input_tuple]\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "    collated_samples = data_collator(tokenized_data_input)\n",
    "    collated_samples['labels'] = collated_fromMLMtoCLM(collated_samples['labels'],instr_lengths)\n",
    "    return collated_samples\n",
    "\n",
    "# def CLM_Collator(tokenized_data_input, tokenizer=GPT2Tokenizer.from_pretrained('gpt2',padding_side=\"right\", add_eos_token=True, add_bos_token=False)):\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "#     data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "#     collated_samples=data_collator(tokenized_data_input)\n",
    "#     collated_samples['labels'] = collated_fromMLMtoCLM(collated_samples['labels'])\n",
    "#     return collated_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "c9tyZRNN4-4p"
   },
   "source": [
    "# TEST FUNCTIONS (DATASET-BATCHES-COLLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "cc655676-e87b-4f86-b2a3-895cdda3db67"
   },
   "outputs": [],
   "source": [
    "def check_input_label_shapes(train_loader):\n",
    "  for pairs in train_loader:\n",
    "      print(pairs['input_ids'].shape, pairs['labels'].shape)\n",
    "\n",
    "  print(pairs['input_ids'][0])\n",
    "  print(pairs['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "b4e43fa8-b6e7-4ddd-b497-186bbb55010f"
   },
   "outputs": [],
   "source": [
    "def collator_decoder_test(train_loader):\n",
    "  for j in train_loader:\n",
    "      tensor = j['input_ids'][0]\n",
    "      filtered_tensor = tensor[tensor != -100]\n",
    "      token_ids = filtered_tensor.tolist()\n",
    "      decoded_string = tokenizer.decode(token_ids, skip_special_tokens=False)\n",
    "      print(\"Decoded Input:\")\n",
    "      print(decoded_string)\n",
    "\n",
    "      tensor = j['labels'][0]\n",
    "      filtered_tensor = tensor[tensor != -100]\n",
    "      token_ids = filtered_tensor.tolist()\n",
    "      decoded_string = tokenizer.decode(token_ids, skip_special_tokens=False)\n",
    "      print(\"\\nDecode Label:\")\n",
    "      print(decoded_string)\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "cYhZs8Kh5Ifr"
   },
   "source": [
    "# DATA + TRAIN_TEST_VAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2ed4654-3a7b-466f-b109-8aceb586d630",
    "outputId": "ebc56636-ea2f-4556-fd12-6418c68a22e7"
   },
   "outputs": [],
   "source": [
    "data = download_data(dir+sub_dir+data_sub_dir+'/IO_Workout_Final.json')\n",
    "\n",
    "print(\"Number Of Samples:\",len(data),\"\\n\")\n",
    "print(\"Initial Sample Example:\\n\",data[1],\"\\n\")\n",
    "for i in range (0,len(data)):\n",
    "  data[i]['input']=str(data[i]['input'])[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "6cbfcb1c-4136-41af-a17f-fcc954693d59"
   },
   "outputs": [],
   "source": [
    "train_data,test_data,val_data = train_test_val_split(data,0.90,0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8347e123-6b24-4c07-8b56-33d4a7f93594",
    "outputId": "c5747355-35af-4e26-8171-9e5064ced6d4"
   },
   "outputs": [],
   "source": [
    "print(\"Training set length:\", len(train_data), \"//Validation set length:\", len(val_data),\"//Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "id": "vywDBymn56i1"
   },
   "source": [
    "# MODEL + TOKENIZER DOWNLOAD (RUN ONE CELL ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "8dkGiemDGZFM"
   },
   "source": [
    "## GPT2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "24aa7d40-c067-4f22-87a8-083f48fbfc04"
   },
   "outputs": [],
   "source": [
    "#BASE GPT2 MODEL FROM HUGGING FACE\n",
    "original_model_name=\"gpt2-medium\"\n",
    "model = GPT2LMHeadModel.from_pretrained(original_model_name)\n",
    "\n",
    "#TOKENIZER + COLLATOR\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "end_of_text_token_id = tokenizer.encode(\"<|endoftext|>\")[0]\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator_fn = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "id": "JuRbIjhX7lWD"
   },
   "outputs": [],
   "source": [
    "#SAVED GPT2 MODEL POST FINE-TUNING (IF EXISTS)\n",
    "original_model_name=\"gpt2-medium\"\n",
    "model_name=dir+sub_dir+'/final_model_'+original_model_name\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "end_of_text_token_id = tokenizer.encode(\"<|endoftext|>\")[0]\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator_fn = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "id": "1cEsoXWJUJOC"
   },
   "outputs": [],
   "source": [
    "def check_unknown_tokens(texts):\n",
    "    unknown_tokens = set()\n",
    "\n",
    "    tokens = tokenizer.encode(texts)\n",
    "    for token in tokens:\n",
    "        if token == 50256:\n",
    "            unknown_tokens.add(token)\n",
    "    return unknown_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "imPDd4sBUL5Y"
   },
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "  texts = str(train_data[10]['output'])\n",
    "  unknown_tokens = check_unknown_tokens(texts)\n",
    "  if len(unknown_tokens)!=0:\n",
    "    print(\"Unknown tokens:\", unknown_tokens)\n",
    "    print(train_data[10]['output'])\n",
    "    print(tokenizer.decode(tokenizer.encode(str(train_data[10]['output']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuhemMAdUNZO",
    "outputId": "f4d7c232-5759-441c-b451-69322ae5f52b"
   },
   "outputs": [],
   "source": [
    "#ADD NEW TOKENS\n",
    "new_token = [\"\"]\n",
    "num_added_toks = tokenizer.add_tokens(new_token)\n",
    "print(f\"Added {num_added_toks} new regular token.\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "TMl-JzKaGU23"
   },
   "source": [
    "## T5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556,
     "referenced_widgets": [
      "ccf1a475dfcc476f80f9d8c1ef56951f",
      "fe87f64b659243a7bb5c81d5b8fbc0f6",
      "7687f98b145d4b5596c2fa2b74e01ed3",
      "c5149b283a484078bed8147c0e5451ca",
      "64cdf3a6741a49eaaa0c1545b809b6ed",
      "3d0a51c7ca314499b2b50c5e5bc4f02c",
      "1b65dfcc01f34d9c8429cad2e91c1811",
      "1ab67373d5cb4f4a966ad4cd15fcec88",
      "1339d6b3ccdb42908ccc6748eaeb1d5c",
      "1a56e091065e4202922f1357c0bd1123",
      "e6d842e34657454a847313635ea96226",
      "94bb18bddfd6496c8c9219b4875a42c0",
      "03e78959e26e4294b92fcf5287e002f9",
      "cc0659bdcc3242b19de119f666881e49",
      "15ab8ed29d534e4dbb8ba22afa6ac43f",
      "95e16c2ae8fa4538ac10e00cdd0bbc5e",
      "eb6098ca43ff449c9ca79cfdf2446195",
      "4d44c6d884a448c8a9ebe6e1ea91417a",
      "705a17b5066745ab8ffd619709999bf6",
      "880bec68188f41a3a1391af922791a4c",
      "c180327f3d9b44a995d5e495f534e971",
      "cf8ce6cb6bfb434e9b1a766042eed4a0"
     ]
    },
    "id": "YMGxUb8IWvWb",
    "outputId": "61caba68-dd97-482e-86fc-31a131dbe9df"
   },
   "outputs": [],
   "source": [
    "#BASE T5 MODEL\n",
    "original_model_name = \"google/long-t5-tglobal-base\"\n",
    "model_name = original_model_name\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator_fn = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "new_tokens = [\"{\", \"}\"]\n",
    "num_added_tokens = tokenizer.add_tokens(new_tokens)\n",
    "print(f\"Added {num_added_tokens} new regular token.\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dp4qd0VWxbw",
    "outputId": "28296857-4d7e-4018-8982-59b4236aa1b2"
   },
   "outputs": [],
   "source": [
    "#SAVED T5 MODEL POST FINE-TUNING (IF EXISTS)\n",
    "original_model_name = \"google/long-t5-tglobal-base\"\n",
    "model_name = dir+sub_dir+'/final_model_'+original_model_name[:3]\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator_fn = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvOfZgadzV-K",
    "outputId": "b6e9f146-3e9f-4fb8-9042-3b9c14670bf0"
   },
   "outputs": [],
   "source": [
    "#LoRA MODEL\n",
    "original_model_name = \"google/long-t5-tglobal-base\"\n",
    "model_name = dir+sub_dir+'/final_model_'+original_model_name+\"LoRA\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator_fn = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "id": "KW0d2MbIQpUR"
   },
   "source": [
    "### CHECK IF T5 MODEL HAS ALL TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "id": "TfID_kS1I3ly"
   },
   "outputs": [],
   "source": [
    "def check_unknown_tokens(texts):\n",
    "    unknown_tokens = set()\n",
    "\n",
    "    tokens = tokenizer.encode(texts)\n",
    "    for token in tokens:\n",
    "        if token == 2:\n",
    "            unknown_tokens.add(token)\n",
    "    return unknown_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "id": "NNkISAFnJHcn"
   },
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "  texts = str(i['output'])\n",
    "  unknown_tokens = check_unknown_tokens(texts)\n",
    "  if len(unknown_tokens)!=0:\n",
    "    print(\"Unknown tokens:\", unknown_tokens)\n",
    "    print(i['output'])\n",
    "    print(tokenizer.decode(tokenizer.encode(str(train_data[10]['output']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnnQqUbEPw30",
    "outputId": "8a63dfb4-1654-4843-8c0e-b83853cc3b78"
   },
   "outputs": [],
   "source": [
    "#ADD NEW TOKENS\n",
    "new_tokens = [\"{\", \"}\"]\n",
    "num_added_tokens = tokenizer.add_tokens(new_tokens)\n",
    "print(f\"Added {num_added_tokens} new regular token.\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "id": "3bDv6XIh1k-y"
   },
   "source": [
    "### T5 LoRA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "XVi0AxPJ1j0z",
    "outputId": "62bd7019-4659-43f5-e707-de6c5bc5d9aa"
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "id": "qELfytst1xqg"
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "LelCz4TWozlN",
    "outputId": "d2631da1-bddd-4e3a-9de3-ffcd49625b0d"
   },
   "outputs": [],
   "source": [
    "#LoRA ONLY\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {
    "id": "OgiA9dnyR_Mz"
   },
   "source": [
    "## Load Model To Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufCJbSUWkDm8",
    "outputId": "af9bc0cf-5c7b-4e8f-deb7-d1f27daea0dd"
   },
   "outputs": [],
   "source": [
    "print(f\"Num of param for {model_name}:\",sum(p.numel() for p in model.parameters()))\n",
    "print(f\"Max Length: {model.config.n_positions}\")\n",
    "\n",
    "model.to(device)  # Move the model to the appropriate device\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "id": "wbd9s2JvHMys"
   },
   "source": [
    "## Model Size Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpD6lCMnHQWB",
    "outputId": "bc9fbd59-1507-42b7-c0df-832e19d6bc3f"
   },
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    return size_all_mb\n",
    "\n",
    "original_model_size = get_model_size(model)\n",
    "print(original_model_size, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Eh_WSjHHnW7",
    "outputId": "4c5e24aa-35c4-4fee-8546-db889f660805"
   },
   "outputs": [],
   "source": [
    "#reduce model to half ONLY FOR INFERENCE\n",
    "\n",
    "if device.type==\"cuda\":\n",
    "  model.half().to(device)\n",
    "\n",
    "def is_fp16(model):\n",
    "    for param in model.parameters():\n",
    "        if param.dtype != torch.float16:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "if is_fp16(model):\n",
    "    print(\"The model is in FP16 precision.\")\n",
    "else:\n",
    "    print(\"The model is not in FP16 precision.\")\n",
    "\n",
    "new_model_size = get_model_size(model)\n",
    "\n",
    "print(new_model_size, \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "id": "XcjR37Cw5bJL"
   },
   "source": [
    "# TOKENIZER + INSTRUCTION-DATASET + COLLATOR INITALIZATION FOR TRAINING\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "id": "bb959d67-704f-478c-b98a-685160ee8f11"
   },
   "outputs": [],
   "source": [
    "#TRAINING AND DATA SETTINGS\n",
    "#GPT2\n",
    "if \"gpt2\" in model_name:\n",
    "  num_workers = 0\n",
    "  batch_size = 8\n",
    "  epochs=9\n",
    "\n",
    "  torch.manual_seed(123)\n",
    "\n",
    "  train_dataset = InstructionDataset_GPT2(train_data, tokenizer)\n",
    "  val_dataset = InstructionDataset_GPT2(val_data, tokenizer)\n",
    "  test_dataset = InstructionDataset_GPT2(test_data, tokenizer)\n",
    "\n",
    "  #FOR TESTING PURPOSES:\n",
    "  train_loader = DataLoader(train_dataset,batch_size=batch_size,collate_fn=data_collator_fn,\n",
    "      shuffle=True,\n",
    "      drop_last=True,\n",
    "      num_workers=num_workers\n",
    "  )\n",
    "\n",
    "elif \"t5\" in model_name or \"goo\" in model_name:\n",
    "  #T5\n",
    "  num_workers = 0\n",
    "  batch_size = 8\n",
    "  epochs=9\n",
    "\n",
    "  torch.manual_seed(123)\n",
    "\n",
    "  train_dataset = InstructionDataset_T5(train_data, tokenizer)\n",
    "  val_dataset = InstructionDataset_T5(val_data, tokenizer)\n",
    "  test_dataset = InstructionDataset_T5(test_data, tokenizer)\n",
    "\n",
    "  #FOR TESTING PURPOSES:\n",
    "  train_loader = DataLoader(train_dataset,batch_size=batch_size,collate_fn=data_collator_fn,\n",
    "      shuffle=True,\n",
    "      drop_last=True,\n",
    "      num_workers=num_workers\n",
    "  )\n",
    "\n",
    "else:\n",
    "  sys.exit(\"Error: model not defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "XrVopIbnX6fi",
    "outputId": "ae5302d6-8739-4019-be43-2c266651d21a"
   },
   "outputs": [],
   "source": [
    "check_input_label_shapes(train_loader)\n",
    "print('\\n\\n\\n')\n",
    "collator_decoder_test(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dWTjVyne1jOV",
    "outputId": "d045623f-4d38-4b7f-8b13-bbdf3b6ef645"
   },
   "outputs": [],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dtO1tU6lxmdW",
    "outputId": "5a598d5a-7bb3-4d91-c06d-bcaa71cd227c"
   },
   "outputs": [],
   "source": [
    "m=0\n",
    "\n",
    "for i in range(0,len(train_dataset)):\n",
    "  if len(train_dataset[i]['labels'])>m:\n",
    "    m=len(train_dataset[i]['labels'])\n",
    "\n",
    "assert m<=model.config.n_positions\n",
    "\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "To-aRhWZ0Cm_",
    "outputId": "bb96691f-5251-4b00-ae01-99803f77222d"
   },
   "outputs": [],
   "source": [
    "print(f\"Max Admissible Length: {model.config.n_positions}\")\n",
    "max_length = tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "id": "pU8YfanMSrtv"
   },
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {
    "id": "knWwDR646F-I"
   },
   "source": [
    "## TRAINING HYPERPARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qd7PCfffUj2A",
    "outputId": "746cdb17-1656-4f10-e452-501afb2b3e61"
   },
   "outputs": [],
   "source": [
    "print(original_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "id": "nCZN35Ra63Hg"
   },
   "outputs": [],
   "source": [
    "if \"gpt2\" in original_model_name:\n",
    "  batch_size = 4\n",
    "  epochs=0.5\n",
    "  training_args = TrainingArguments(\n",
    "      output_dir=(dir+sub_dir+'results_'+original_model_name),\n",
    "      num_train_epochs=epochs,\n",
    "      per_device_train_batch_size=batch_size,\n",
    "      per_device_eval_batch_size=2*batch_size,\n",
    "      warmup_steps=int(0.1* epochs* (len(train_dataset)//batch_size)),\n",
    "      weight_decay=0.1,\n",
    "      logging_dir=dir+sub_dir+'logs_'+original_model_name,\n",
    "      logging_steps=100,\n",
    "      do_train=True,\n",
    "      do_eval=True,\n",
    "      eval_strategy=\"steps\",\n",
    "      eval_steps=int(len(train_dataset)/10),\n",
    "      save_strategy=\"steps\",\n",
    "      save_steps=2*int(len(train_dataset)/10),\n",
    "      save_total_limit=3,\n",
    "      load_best_model_at_end=True,\n",
    "      resume_from_checkpoint=True,\n",
    "      lr_scheduler_type='linear',\n",
    "      gradient_accumulation_steps=2,\n",
    "      max_grad_norm=1.0,\n",
    "      learning_rate=7.5e-5,\n",
    "  )\n",
    "\n",
    "  trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset= val_dataset,\n",
    "    data_collator=data_collator_fn,\n",
    "  )\n",
    "\n",
    "\n",
    "if \"t5\" in original_model_name:\n",
    "  batch_size = 2\n",
    "  epochs=9\n",
    "  fp16_bool=False #TRUE ONLY IF USING GPU\n",
    "  training_args = Seq2SeqTrainingArguments(\n",
    "      output_dir=(dir+sub_dir+'results_'+original_model_name),\n",
    "      num_train_epochs=epochs,\n",
    "      per_device_train_batch_size=batch_size,\n",
    "      per_device_eval_batch_size=2*batch_size,\n",
    "      warmup_steps=int(0.1* epochs* (len(train_dataset)//batch_size)),\n",
    "      weight_decay=0.1,\n",
    "      logging_dir=dir+sub_dir+'logs_'+original_model_name,\n",
    "      logging_steps=100,\n",
    "      do_train=True,\n",
    "      do_eval=True,\n",
    "      eval_strategy=\"steps\",\n",
    "      eval_steps=int(len(train_dataset)/10),\n",
    "      save_strategy=\"steps\",\n",
    "      save_steps=2*int(len(train_dataset)/10),\n",
    "      save_total_limit=3,\n",
    "      load_best_model_at_end=True,\n",
    "      resume_from_checkpoint=True,\n",
    "      lr_scheduler_type='linear',\n",
    "      gradient_accumulation_steps=4, #CHANGE DEPENDING ON BATCH SIZE\n",
    "      max_grad_norm=1.0,\n",
    "      learning_rate=9e-5,\n",
    "  )\n",
    "\n",
    "  trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset= val_dataset,\n",
    "    data_collator=data_collator_fn,\n",
    "    tokenizer=tokenizer\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {
    "id": "Yo6iA0LT6Yvb"
   },
   "source": [
    "## TRAINING + EVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {
    "id": "idFHJiPCNKqb"
   },
   "source": [
    "### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "id": "VwrB9M0DA2_w"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "rB8L4Bi8K4LZ",
    "outputId": "0d37ecf8-7470-4c7a-e87a-9ae94b4802fd"
   },
   "outputs": [],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {
    "id": "hMvzxeM5LB7L"
   },
   "source": [
    "### T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "qJ6HTzWTLFTV",
    "outputId": "b15fdba6-918a-48f0-9f54-0fdeed291b82"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "3buaMckxLRqe",
    "outputId": "9af03798-005b-4a8f-d9cc-ebc494f8060f"
   },
   "outputs": [],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {
    "id": "SyF4t5-R63v0"
   },
   "source": [
    "# SAVING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "id": "nmQkA1InDiFb"
   },
   "outputs": [],
   "source": [
    "append_filename=\"Final\" #AWS or LoRA ETC\n",
    "filename = dir+sub_dir+'final_model_'+original_model_name[:3]+append_filename\n",
    "if os.path.exists(filename):\n",
    "    m=input(\"are you sure you want to overwrite file? reply with 'yes' or 'no'\")\n",
    "    if m.lower()=='yes':\n",
    "        model.save_pretrained(filename,safe_serialization=False)\n",
    "        tokenizer.save_pretrained(filename)\n",
    "\n",
    "else:\n",
    "    model.save_pretrained(filename,safe_serialization=False)\n",
    "    tokenizer.save_pretrained(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {
    "id": "40buTMXM6pUF"
   },
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {
    "id": "lTxpAMEnM5Lv"
   },
   "source": [
    "### GPT2 FINETUNED OUTPUT EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "gFgZ_PXcK4NO",
    "outputId": "1b5d0b6a-659e-4eda-923c-2c199ba8ebb1"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model_outputs=[]\n",
    "data_to_use = train_data[74:75]\n",
    "\n",
    "for i in tqdm(range(len(data_to_use))):\n",
    "  in_test = data_to_use[i]\n",
    "  sample_out = data_to_use[i]['output']\n",
    "  in_test=format_model_input(in_test)\n",
    "  input_ids = tokenizer.encode(in_test, return_tensors=\"pt\").to(device)\n",
    "  # output = model.generate(\n",
    "  #     input_ids=input_ids,\n",
    "  #     eos_token_id=50256,\n",
    "  #     max_length=len(input_ids) + 200,\n",
    "  #     num_return_sequences=1,\n",
    "  #     early_stopping=True,\n",
    "  #     pad_token_id=50256,\n",
    "  # )\n",
    "  output = model.generate(\n",
    "      input_ids=input_ids,\n",
    "      eos_token_id=50256,\n",
    "      max_length=len(input_ids) + 300,\n",
    "      num_beams=3,\n",
    "      num_return_sequences=1,\n",
    "      early_stopping=True,\n",
    "      pad_token_id=50256,\n",
    "      #repetition_penalty=1.5,  #TO EXPERIMENT WITH\n",
    "  )\n",
    "\n",
    "  decoded_output=tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "  stop_sequence = \"### Response\"\n",
    "  stop_index = decoded_output.find(stop_sequence, decoded_output.find(stop_sequence) + len(stop_sequence))\n",
    "  if stop_index != -1:\n",
    "      trimmed_output = decoded_output[:stop_index]\n",
    "  else:\n",
    "      trimmed_output = decoded_output\n",
    "\n",
    "  print('expected output:',sample_out,'model output:',trimmed_output,'\\n',sep='\\n')\n",
    "  model_outputs.append(trimmed_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {
    "id": "kqDacyDTM9-c"
   },
   "source": [
    "### T5 FINETUNED OUTPUT EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__vFRKNMK9m5",
    "outputId": "ac32cae3-589a-4f16-c89b-5f481f2f11ae"
   },
   "outputs": [],
   "source": [
    "for i in val_data:\n",
    "  if i['input']=='':\n",
    "    print(\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "id": "XdO8uOWSCaK7"
   },
   "outputs": [],
   "source": [
    "l=[{},{},{}]\n",
    "l[0]['input']='foam roll'\n",
    "l[1]['input']=\"warmup\"\n",
    "l[2]['input']='foam roll warmup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hs2eCJO_NIPx",
    "outputId": "91c4988f-8470-47a3-a8be-10af30b7a0eb"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model_outputs=[]\n",
    "data_to_use = np.random.choice(train_data, 420, replace=False)\n",
    "#data_to_use = test_data[6:7]\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(len(data_to_use))):\n",
    "  in_test = data_to_use[i]\n",
    "  in_test=format_model_input(in_test)\n",
    "  #print(\"input:\\n\",in_test) #UNCOMMENT TO PRINT\n",
    "  input_ids = tokenizer.encode(in_test, return_tensors=\"pt\").to(device)\n",
    "\n",
    "  start_time = time.time()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        eos_token_id=1,\n",
    "        max_length= 1200,\n",
    "        num_beams=2,\n",
    "        num_return_sequences=1,\n",
    "        early_stopping=True,\n",
    "        repetition_penalty=3.0,  #TO EXPERIMENT WITH\n",
    "    )\n",
    "  end_time = time.time()\n",
    "\n",
    "  decoded_output=tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "  stop_sequence = \"### Response\"\n",
    "  stop_index = decoded_output.find(stop_sequence, decoded_output.find(stop_sequence) + len(stop_sequence))\n",
    "  if stop_index != -1:\n",
    "      trimmed_output = decoded_output[:stop_index]\n",
    "  else:\n",
    "      trimmed_output = decoded_output\n",
    "\n",
    "  #print('model output:',trimmed_output,'\\n',sep='\\n') #UNCOMMENT TO SEE OUTPUT\n",
    "  model_outputs.append(trimmed_output)\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "#print(f\" model inference time: {inference_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {
    "id": "LGGIDI23-W9Q"
   },
   "source": [
    "### SAVE MODEL OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "id": "7-iqaARr-c70"
   },
   "outputs": [],
   "source": [
    "if len(model_outputs)==len(train_data[:420]):\n",
    "  output_file=dir+sub_dir+'final_model_'+original_model_name[:3]+'_model_outputs_train.json'\n",
    "\n",
    "elif data_to_use==test_data:\n",
    "  output_file=dir+sub_dir+'final_model_'+original_model_name[:3]+'_model_outputs_test.json'\n",
    "\n",
    "elif data_to_use==val_data:\n",
    "  output_file=dir+sub_dir+'final_model_'+original_model_name[:3]+'_model_outputs_val.json'\n",
    "\n",
    "else:\n",
    "  sys.exit(\"Error: lengths do not match with original dataset\")\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "  json.dump(model_outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {
    "id": "1wUnkOdGotz0"
   },
   "source": [
    "# TESTING + DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "id": "466xMbz5cC2H"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {
    "id": "2vpNvGxOwAh7"
   },
   "source": [
    "### TESTING + TRANSFORMATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "id": "wzQjPfMKb0GV"
   },
   "outputs": [],
   "source": [
    "def convert_output_to_list(model_outputs,model_name):\n",
    "  model_outputs_list=[]\n",
    "  if \"gpt2\" in model_name:\n",
    "    for i,generated in enumerate(model_outputs):\n",
    "      s = generated\n",
    "\n",
    "      start_index = s.find(\"### Response\")\n",
    "      if start_index != -1:\n",
    "        s = s[start_index:]\n",
    "\n",
    "      s = s.replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "      end_index = s.find(']}]') #POST PROCESSING\n",
    "      if end_index != -1:\n",
    "        s = s[:end_index + 3]\n",
    "\n",
    "      try:\n",
    "          s = ast.literal_eval(s)\n",
    "\n",
    "      except (ValueError, SyntaxError):\n",
    "          print(f\"ERROR: Output at index {i} is invalid and cannot be parsed.\")\n",
    "\n",
    "      if type(s) != list or not all(isinstance(item, dict) for item in s):\n",
    "        print(i,s,\"ERROR: not dict or not list\")\n",
    "\n",
    "      else:\n",
    "        model_outputs_list.append(s)\n",
    "\n",
    "\n",
    "  elif \"goo\" in model_name:\n",
    "    for i,generated in enumerate(model_outputs):\n",
    "      s = generated\n",
    "      s = s.replace(\"</s>\", \"\").strip()\n",
    "      s = s.strip(\"<pad> ### Response: \")\n",
    "\n",
    "      try:\n",
    "          s = ast.literal_eval(s)\n",
    "\n",
    "      except (ValueError, SyntaxError):\n",
    "        last_bracket_index = s.rfind('}')\n",
    "        if last_bracket_index != -1:\n",
    "            s = s[:last_bracket_index + 1]\n",
    "            s += ']}'\n",
    "            try:\n",
    "                s=ast.literal_eval(s)\n",
    "            except (ValueError, SyntaxError):\n",
    "                print(f\"ERROR: Output at index {i} is invalid and cannot be parsed.\")\n",
    "\n",
    "      if type(s) != dict:\n",
    "        print(i,s,\"ERROR: not dict or not list\")\n",
    "\n",
    "      else:\n",
    "        model_outputs_list.append(s)\n",
    "  else:\n",
    "    return \"ERROR: Get Model Name\"\n",
    "\n",
    "  print(f\"{len(model_outputs_list)} outputs converted correctly to list of dicts out of {len(model_outputs)} model outputs\")\n",
    "  return model_outputs_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "id": "xBRw6T6qfijT"
   },
   "outputs": [],
   "source": [
    "def check_parameters_correctness(model_outputs_list, param_list=['reps,time,distance']):\n",
    "    required_keys = {'exercise', 'sets'}\n",
    "    c=0\n",
    "    k=0\n",
    "    for i,d in enumerate(model_outputs_list):\n",
    "      for keys in d:\n",
    "          for j, dictionary in enumerate(d[keys]):\n",
    "              k=k+1\n",
    "              if not required_keys.issubset(dictionary.keys()):\n",
    "                  print(f\"ERROR: Dictionary at index [{i}][{keys}][[{j}] must have at least the keys {required_keys}.\")\n",
    "                  c=c+1\n",
    "                  continue\n",
    "\n",
    "\n",
    "              if not any(param in dictionary for param in param_list):\n",
    "                  print(f\"ERROR: Dictionary at index [{i}][{keys}][[{j}] must have at least one of the keys from {param_list}.\")\n",
    "                  c=c+1\n",
    "                  continue\n",
    "\n",
    "              allowed_keys = required_keys.union(param_list)\n",
    "              if not set(dictionary.keys()).issubset(allowed_keys):\n",
    "                  print(f\"ERROR: Dictionary at index [{i}][{keys}][[{j}] must only have keys from {allowed_keys}.\")\n",
    "                  c=c+1\n",
    "                  continue\n",
    "    print(f\"inconsistency in keys for {c} out of {k} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "id": "74OVAi4zl_oe"
   },
   "outputs": [],
   "source": [
    "def check_set_and_param_consistency(model_outputs_list,param_list=['reps,time,distance']): #MODIFY WHEN ADD PARMETERS OTHER THAN REPS (For ALL params other than exercise, #sets must be == len(param))\n",
    "  c=0\n",
    "  k=0\n",
    "  for i,d in enumerate(model_outputs_list):\n",
    "    for keys in d:\n",
    "        for j, dictionary in enumerate(d[keys]):\n",
    "          sets = dictionary['sets']\n",
    "          for param in param_list:\n",
    "              k=k+1\n",
    "              if param in dictionary and sets != len(dictionary[param]):\n",
    "                  c += 1\n",
    "                  print(f\"ERROR: Dictionary at index [{i}][{keys}][{j}] has #sets != len({param})\")\n",
    "\n",
    "  print(f\"inonsistency in sets and params for {c} out of {k} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {
    "id": "N-bQ8P3ro0PV"
   },
   "outputs": [],
   "source": [
    "def no_consecutive_same_exercise(model_outputs_list):\n",
    "  c=0\n",
    "  m=0\n",
    "  for i,d in enumerate(model_outputs_list):\n",
    "    for keys in d:\n",
    "      m=m+1\n",
    "      k=1\n",
    "      for j in range(0,len(d[keys])-1):\n",
    "        if d[keys][j]['exercise']==d[keys][j+1]['exercise']:\n",
    "          if k==1:\n",
    "            print(f\"ERROR: Duplicated exercise at model output index {i}\")\n",
    "            c=c+1\n",
    "            k=0\n",
    "\n",
    "  print(f\"same exercise repeated consecutively for {c} out of {m} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {
    "id": "Yzg32pIqEnn1"
   },
   "outputs": [],
   "source": [
    "def remove_consecutive_duplicates(model_outputs_list):\n",
    "    for i in range(len(model_outputs_list)):\n",
    "        for key in model_outputs_list[i]:\n",
    "            j = 0\n",
    "            while j < len(model_outputs_list[i][key]) - 1:\n",
    "                if model_outputs_list[i][key][j]['exercise'] == model_outputs_list[i][key][j + 1]['exercise']:\n",
    "                    del model_outputs_list[i][key][j + 1]\n",
    "                else:\n",
    "                    j += 1\n",
    "    return model_outputs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {
    "id": "FdajuCAjmT7U"
   },
   "source": [
    "### CHOOSE MODEL AND DATASET OUTPUTS. !!!!!!DO NOT RUN FIRST CELL IF YOU WANT THE VALUES FROM \"{MODEL}FINETUNED OUTPUT EXAMPLES\" EXECUTION!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {
    "id": "pJvuzbR_3M3X"
   },
   "source": [
    "#### SELECT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0bv4zDRllhy",
    "outputId": "6dded6da-b118-4ff3-a0d4-cda0854320ed"
   },
   "outputs": [],
   "source": [
    "#MODEL OUTPUTS\n",
    "file_to_read = dir+sub_dir+'final_model_goo_model_outputs_train.json'\n",
    "with open(file_to_read, 'r') as f:\n",
    "    model_outputs = json.load(f)\n",
    "print(len(model_outputs))\n",
    "print(model_outputs[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVeSoCl49u0V",
    "outputId": "741a0a2c-ece8-4f1b-8647-88c1cf0da67b"
   },
   "outputs": [],
   "source": [
    "using_data=train_data\n",
    "data_outputs = [using_data[i]['output'] for i in range(len(using_data))]\n",
    "print(len(data_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "id": "tK7YEbO66NgT"
   },
   "outputs": [],
   "source": [
    "model_outputs_list=[]\n",
    "for i in data:\n",
    "  model_outputs_list.append(i['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {
    "id": "1pQqd0QMb60S"
   },
   "source": [
    "### GPT2 RUN TESTS + TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bde84164-49a7-466c-a388-24b7797a1d54",
    "outputId": "a2fc9075-8a3b-458b-e806-4dabcc5ef4af"
   },
   "outputs": [],
   "source": [
    "model_name=\"goo\"\n",
    "model_outputs_list=convert_output_to_list(model_outputs,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTrd1s7kW0r6",
    "outputId": "e35a1ae8-f77e-4d6b-8cfe-822ed8dbc604"
   },
   "outputs": [],
   "source": [
    "for i in model_outputs_list:\n",
    "  for l in i:\n",
    "    print(i[l])\n",
    "    break\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "_2Ax1UlXg3zY",
    "outputId": "b8997096-323d-4d30-fdd4-f0683b10c816"
   },
   "outputs": [],
   "source": [
    "check_parameters_correctness(model_outputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pf2_D-t5g4wj",
    "outputId": "e5ec6fda-b3a2-4da0-fd26-98aa6249ca00"
   },
   "outputs": [],
   "source": [
    "check_set_and_param_consistency(model_outputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2iVBia_9hNat",
    "outputId": "0c946bb2-c908-4358-cdc2-b80dcc4bfd04"
   },
   "outputs": [],
   "source": [
    "no_consecutive_same_exercise(model_outputs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {
    "id": "DSg_c6AY4-qA"
   },
   "source": [
    "### GPT2 DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {
    "id": "FhMtuvC4C6R4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "h-UN45UJ5Fmi",
    "outputId": "323b03ab-43d5-406b-a033-851b936b9da5"
   },
   "outputs": [],
   "source": [
    "gpt2df=output_list_to_df(model_outputs_list)\n",
    "gpt2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVxwcIGi8TaF",
    "outputId": "7a951197-67d9-4b2e-b4de-99e0a9ffcc99"
   },
   "outputs": [],
   "source": [
    "#DATA ANALYSIS ON EXERCISES\n",
    "print(\"##############GPT2 OUTPUT##############\")\n",
    "total_number_of_ex = gpt2df['exercise'].count()\n",
    "max_number_of_ex_per_block = gpt2df.groupby('block')['exercise'].count().max()\n",
    "average_number_of_ex_per_outer_list = gpt2df.groupby('block')['exercise'].count().mean()\n",
    "median_number_of_ex_per_outer_list = gpt2df.groupby('block')['exercise'].count().median()\n",
    "std_dev_of_ex_per_outer_list = gpt2df.groupby('block')['exercise'].count().std()\n",
    "\n",
    "print(f\"Total number of exercises: {total_number_of_ex}\")\n",
    "print(f\"Max number of exercises per block: {max_number_of_ex_per_block}\")\n",
    "print(f\"Average number of exercises per block: {average_number_of_ex_per_outer_list}\")\n",
    "print(f\"Median number of exercises per block: {median_number_of_ex_per_outer_list}\")\n",
    "print(f\"Standard deviation of exercises per block: {std_dev_of_ex_per_outer_list}\")\n",
    "\n",
    "print(\"\\n##############TRAINING DATASET OUTPUT##############\")\n",
    "total_number_of_ex = main_dataset_df['exercise'].count()\n",
    "max_number_of_ex_per_block = main_dataset_df.groupby('block')['exercise'].count().max()\n",
    "average_number_of_ex_per_outer_list = main_dataset_df.groupby('block')['exercise'].count().mean()\n",
    "median_number_of_ex_per_outer_list = main_dataset_df.groupby('block')['exercise'].count().median()\n",
    "std_dev_of_ex_per_outer_list = main_dataset_df.groupby('block')['exercise'].count().std()\n",
    "\n",
    "print(f\"Total number of exercises: {total_number_of_ex}\")\n",
    "print(f\"Max number of exercises per block: {max_number_of_ex_per_block}\")\n",
    "print(f\"Average number of exercises per block: {average_number_of_ex_per_outer_list}\")\n",
    "print(f\"Median number of exercises per block: {median_number_of_ex_per_outer_list}\")\n",
    "print(f\"Standard deviation of exercises per block: {std_dev_of_ex_per_outer_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcCexY048abP",
    "outputId": "6256a0a7-3ac1-4c60-9184-2780915c6ba8"
   },
   "outputs": [],
   "source": [
    "#DATA ANALYSIS ON SETS\n",
    "print(\"##############GPT2 OUTPUT##############\")\n",
    "total_sets = gpt2df['sets'].sum()\n",
    "max_sets_per_block = gpt2df.groupby('block')['sets'].sum().max()\n",
    "average_sets_per_outer_list = gpt2df.groupby('block')['sets'].sum().mean()\n",
    "median_sets_per_outer_list = gpt2df.groupby('block')['sets'].sum().median()\n",
    "std_dev_sets_per_outer_list = gpt2df.groupby('block')['sets'].sum().std()\n",
    "\n",
    "print(f\"Total number of sets: {total_sets}\")\n",
    "print(f\"Max number of sets per block: {max_sets_per_block}\")\n",
    "print(f\"Average number of sets per block: {average_sets_per_outer_list}\")\n",
    "print(f\"Median number of sets per block: {median_sets_per_outer_list}\")\n",
    "print(f\"Standard deviation of sets per block: {std_dev_sets_per_outer_list}\")\n",
    "\n",
    "print(\"\\n##############TRAINING DATASET OUTPUT##############\")\n",
    "total_sets = main_dataset_df['sets'].sum()\n",
    "max_sets_per_block = main_dataset_df.groupby('block')['sets'].sum().max()\n",
    "average_sets_per_outer_list = main_dataset_df.groupby('block')['sets'].sum().mean()\n",
    "median_sets_per_outer_list = main_dataset_df.groupby('block')['sets'].sum().median()\n",
    "std_dev_sets_per_outer_list = main_dataset_df.groupby('block')['sets'].sum().std()\n",
    "\n",
    "print(f\"Total number of sets: {total_sets}\")\n",
    "print(f\"Max number of sets per block: {max_sets_per_block}\")\n",
    "print(f\"Average number of sets per block: {average_sets_per_outer_list}\")\n",
    "print(f\"Median number of sets per block: {median_sets_per_outer_list}\")\n",
    "print(f\"Standard deviation of sets per block: {std_dev_sets_per_outer_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSSeFvmw8dNo",
    "outputId": "274b86f7-3c1b-405a-cd4d-645f63ce9a07"
   },
   "outputs": [],
   "source": [
    "#DATA ANALYSIS ON REPS\n",
    "print(\"##############GPT2 OUTPUT##############\")\n",
    "gpt2df['max_reps'] = gpt2df['reps'].apply(lambda x: max(x) if x else 0)\n",
    "gpt2df['mean_reps'] = gpt2df['reps'].apply(lambda x: sum(x) / len(x) if x else 0)\n",
    "gpt2df['total_reps'] = gpt2df['reps'].apply(sum)\n",
    "\n",
    "mean_reps = gpt2df['mean_reps'].mean()\n",
    "median_reps = gpt2df['mean_reps'].median()\n",
    "total_reps = gpt2df['total_reps'].sum()\n",
    "max_reps_per_block = gpt2df.groupby('block')['total_reps'].sum().max()\n",
    "average_reps_per_outer_list = gpt2df.groupby('block')['total_reps'].sum().mean()\n",
    "median_reps_per_outer_list = gpt2df.groupby('block')['total_reps'].sum().median()\n",
    "std_dev_reps_per_outer_list = gpt2df.groupby('block')['total_reps'].sum().std()\n",
    "\n",
    "print(f\"Mean number of average number of reps per exercise: {mean_reps}\")\n",
    "print(f\"Median number of average number of reps per exercise: {median_reps}\")\n",
    "print(f\"Total number of reps: {total_reps}\")\n",
    "print(f\"Max number of reps per block: {max_reps_per_block}\")\n",
    "print(f\"Average number of reps per block: {average_reps_per_outer_list}\")\n",
    "print(f\"Median number of reps per block: {median_reps_per_outer_list}\")\n",
    "print(f\"Standard deviation of reps per block: {std_dev_reps_per_outer_list}\")\n",
    "\n",
    "print(\"\\n##############TRAINING DATASET OUTPUT##############\")\n",
    "\n",
    "main_dataset_df['max_reps'] = main_dataset_df['reps'].apply(lambda x: max(x) if x else 0)\n",
    "main_dataset_df['mean_reps'] = main_dataset_df['reps'].apply(lambda x: sum(x) / len(x) if x else 0)\n",
    "main_dataset_df['total_reps'] = main_dataset_df['reps'].apply(sum)\n",
    "\n",
    "mean_reps = main_dataset_df['mean_reps'].mean()\n",
    "median_reps = main_dataset_df['mean_reps'].median()\n",
    "total_reps = main_dataset_df['total_reps'].sum()\n",
    "max_reps_per_block = main_dataset_df.groupby('block')['total_reps'].sum().max()\n",
    "average_reps_per_outer_list = main_dataset_df.groupby('block')['total_reps'].sum().mean()\n",
    "median_reps_per_outer_list = main_dataset_df.groupby('block')['total_reps'].sum().median()\n",
    "std_dev_reps_per_outer_list = main_dataset_df.groupby('block')['total_reps'].sum().std()\n",
    "\n",
    "print(f\"Mean number of average number of reps per exercise: {mean_reps}\")\n",
    "print(f\"Median number of average number of reps per exercise: {median_reps}\")\n",
    "print(f\"Total number of reps: {total_reps}\")\n",
    "print(f\"Max number of reps per block: {max_reps_per_block}\")\n",
    "print(f\"Average number of reps per block: {average_reps_per_outer_list}\")\n",
    "print(f\"Median number of reps per block: {median_reps_per_outer_list}\")\n",
    "print(f\"Standard deviation of reps per block: {std_dev_reps_per_outer_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {
    "id": "zY3dt7Dl6etI"
   },
   "source": [
    "### T5 RUN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q28ylfXncYye",
    "outputId": "47f1dae4-d953-4014-80dd-9e3722a7959d"
   },
   "outputs": [],
   "source": [
    "model_name=\"goo\"\n",
    "model_outputs_list=convert_output_to_list(model_outputs,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKooWfqm6TB-",
    "outputId": "6f2370b2-158d-440a-f4da-bf1d11a9c320"
   },
   "outputs": [],
   "source": [
    "check_parameters_correctness(model_outputs_list,['reps','time','distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-tB_eRQ6UyM",
    "outputId": "93d5bf10-d4bd-4e0a-965c-22d137ed8647"
   },
   "outputs": [],
   "source": [
    "check_set_and_param_consistency(model_outputs_list,['reps','time','distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTSo1PHA6Wym",
    "outputId": "a9107288-4ab9-4e07-ded0-33ea23515937"
   },
   "outputs": [],
   "source": [
    "no_consecutive_same_exercise(model_outputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {
    "id": "TmD3bW5BFbNZ"
   },
   "outputs": [],
   "source": [
    "model_outputs_list = remove_consecutive_duplicates(model_outputs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {
    "id": "0by45f6YwHSx"
   },
   "source": [
    "### T5 DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzp1Ca474oUG",
    "outputId": "bddcff2d-9252-4c6f-813b-4197fb7b1bfd"
   },
   "outputs": [],
   "source": [
    "arr=np.zeros((len(model_outputs_list),1))\n",
    "for i,d in enumerate(model_outputs_list):\n",
    "  arr[i]=len(d.keys())\n",
    "\n",
    "average = np.mean(arr)\n",
    "median = np.median(arr)\n",
    "std_dev = np.std(arr)\n",
    "max_value = np.max(arr)\n",
    "min_value = np.min(arr)\n",
    "\n",
    "print(\"MODEL OUT STATS FOR NUMBER OF BLOCKS:\")\n",
    "print(f\"Average (Mean): {average}\")\n",
    "print(f\"Median: {median}\")\n",
    "print(f\"Standard Deviation: {std_dev}\")\n",
    "print(f\"Maximum Value: {max_value}\")\n",
    "print(f\"Minimum Value: {min_value}\")\n",
    "\n",
    "data=data_outputs\n",
    "arr=np.zeros((len(data),1))\n",
    "for i,d in enumerate(data):\n",
    "  arr[i]=len(d.keys())\n",
    "\n",
    "average = np.mean(arr)\n",
    "median = np.median(arr)\n",
    "std_dev = np.std(arr)\n",
    "max_value = np.max(arr)\n",
    "min_value = np.min(arr)\n",
    "print()\n",
    "print(\"TRAIN DATA STATS FOR NUMBER OF BLOCKS:\")\n",
    "print(f\"Average (Mean): {average}\")\n",
    "print(f\"Median: {median}\")\n",
    "print(f\"Standard Deviation: {std_dev}\")\n",
    "print(f\"Maximum Value: {max_value}\")\n",
    "print(f\"Minimum Value: {min_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfGuyZU3s7iq",
    "outputId": "d75c0c96-0d6d-464d-84c0-639f1e73e968"
   },
   "outputs": [],
   "source": [
    "arr = np.array([])\n",
    "for i,d in enumerate(model_outputs_list):\n",
    "  for keys in d:\n",
    "      arr=np.append(arr,len(d[keys]))\n",
    "\n",
    "average = np.mean(arr)\n",
    "median = np.median(arr)\n",
    "std_dev = np.std(arr)\n",
    "max_value = np.max(arr)\n",
    "min_value = np.min(arr)\n",
    "\n",
    "print(\"MODEL OUT STATS FOR NUMBER OF EXERCISES PER BLOCK:\")\n",
    "print(f\"Average (Mean): {average}\")\n",
    "print(f\"Median: {median}\")\n",
    "print(f\"Standard Deviation: {std_dev}\")\n",
    "print(f\"Maximum Value: {max_value}\")\n",
    "print(f\"Minimum Value: {min_value}\")\n",
    "\n",
    "arr = np.array([])\n",
    "data=data_outputs\n",
    "for i,d in enumerate(data):\n",
    "  for keys in d:\n",
    "      arr=np.append(arr,len(d[keys]))\n",
    "\n",
    "average = np.mean(arr)\n",
    "median = np.median(arr)\n",
    "std_dev = np.std(arr)\n",
    "max_value = np.max(arr)\n",
    "min_value = np.min(arr)\n",
    "print()\n",
    "print(\"TRAIN DATA STATS FOR NUMBER OF EXERCISES PER BLOCKS:\")\n",
    "print(f\"Average (Mean): {average}\")\n",
    "print(f\"Median: {median}\")\n",
    "print(f\"Standard Deviation: {std_dev}\")\n",
    "print(f\"Maximum Value: {max_value}\")\n",
    "print(f\"Minimum Value: {min_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9rTemcCu9gl",
    "outputId": "6ee77810-4673-4cca-e310-19e91df40d12"
   },
   "outputs": [],
   "source": [
    "arr = np.array([])\n",
    "for i,d in enumerate(model_outputs_list):\n",
    "  for keys in d:\n",
    "    for j in d[keys]:\n",
    "      arr=np.append(arr,j['sets'])\n",
    "\n",
    "average = np.mean(arr)\n",
    "median = np.median(arr)\n",
    "std_dev = np.std(arr)\n",
    "max_value = np.max(arr)\n",
    "min_value = np.min(arr)\n",
    "\n",
    "print(\"MODEL OUT STATS FOR NUMBER OF SETS PER BLOCK:\")\n",
    "print(f\"Average (Mean): {average}\")\n",
    "print(f\"Median: {median}\")\n",
    "print(f\"Standard Deviation: {std_dev}\")\n",
    "print(f\"Maximum Value: {max_value}\")\n",
    "print(f\"Minimum Value: {min_value}\")\n",
    "\n",
    "arr = np.array([])\n",
    "data=data_outputs\n",
    "for i,d in enumerate(data):\n",
    "  for keys in d:\n",
    "    for j in d[keys]:\n",
    "      arr=np.append(arr,j['sets'])\n",
    "\n",
    "average = np.mean(arr)\n",
    "median = np.median(arr)\n",
    "std_dev = np.std(arr)\n",
    "max_value = np.max(arr)\n",
    "min_value = np.min(arr)\n",
    "print()\n",
    "print(\"TRAIN DATA STATS FOR NUMBER OF SETS PER BLOCKS:\")\n",
    "print(f\"Average (Mean): {average}\")\n",
    "print(f\"Median: {median}\")\n",
    "print(f\"Standard Deviation: {std_dev}\")\n",
    "print(f\"Maximum Value: {max_value}\")\n",
    "print(f\"Minimum Value: {min_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {
    "id": "y2rq9BjHozUK"
   },
   "source": [
    "# EVALUATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHoSJhRipDg3",
    "outputId": "0f76093a-5de3-4abc-8167-8f0a297308c7"
   },
   "outputs": [],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXRpH1slo3vS",
    "outputId": "3df59bc0-a9cd-4907-f54b-ce6544faad8c"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {
    "id": "kqhE7DfZzSoI"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {
    "id": "_xZoogz8o_I8"
   },
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, hypothesis):\n",
    "    reference_tokens = [nltk.word_tokenize(reference)]\n",
    "    hypothesis_tokens = nltk.word_tokenize(hypothesis)\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return sentence_bleu(reference_tokens, hypothesis_tokens, smoothing_function=smoothie)\n",
    "\n",
    "def calculate_rouge(reference, hypothesis):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    return scorer.score(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {
    "id": "LlsYrc38Gpla"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kO99PnpNzVvn",
    "outputId": "eb96ce4d-8ad9-4758-dc0d-6c651cc7d030"
   },
   "outputs": [],
   "source": [
    "reference_texts = [str(i['output']) for i in train_data]\n",
    "print(len(reference_texts), len(model_outputs))\n",
    "for i in range(len(model_outputs)):\n",
    "  model_outputs[i]=model_outputs[i].strip(\"<pad> ### Response: \")\n",
    "  model_outputs[i]=model_outputs[i].replace(\" { \", \"{\").replace(\" }\", \"}\").replace(\",\",\", \").replace(\"} \",\"}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WnxRLhVX-yzb",
    "outputId": "b8e8f99a-3d4c-4197-a8e9-d49b22526c64"
   },
   "outputs": [],
   "source": [
    "bleu_scores = []\n",
    "rouge1_scores = []\n",
    "rouge2_scores = []\n",
    "rougeL_scores = []\n",
    "\n",
    "for ref, gen in zip(reference_texts, model_outputs):\n",
    "\n",
    "    bleu_score = calculate_bleu(ref, gen)\n",
    "    rouge_scores = calculate_rouge(ref, gen)\n",
    "\n",
    "    bleu_scores.append(bleu_score)\n",
    "    rouge1_scores.append(rouge_scores['rouge1'].fmeasure)\n",
    "    rouge2_scores.append(rouge_scores['rouge2'].fmeasure)\n",
    "    rougeL_scores.append(rouge_scores['rougeL'].fmeasure)\n",
    "\n",
    "\n",
    "\n",
    "bleu_mean = np.mean(bleu_scores)\n",
    "bleu_std = np.std(bleu_scores)\n",
    "\n",
    "rouge1_mean = np.mean(rouge1_scores)\n",
    "rouge1_std = np.std(rouge1_scores)\n",
    "\n",
    "rouge2_mean = np.mean(rouge2_scores)\n",
    "rouge2_std = np.std(rouge2_scores)\n",
    "\n",
    "rougeL_mean = np.mean(rougeL_scores)\n",
    "rougeL_std = np.std(rougeL_scores)\n",
    "\n",
    "print(f\"Average BLEU Score: {bleu_mean:.4f} ± {bleu_std:.4f}\")\n",
    "print(f\"Average ROUGE-1 F1 Score: {rouge1_mean:.4f} ± {rouge1_std:.4f}\")\n",
    "print(f\"Average ROUGE-2 F1 Score: {rouge2_mean:.4f} ± {rouge2_std:.4f}\")\n",
    "print(f\"Average ROUGE-L F1 Score: {rougeL_mean:.4f} ± {rougeL_std:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QnAvtTLw5hRq",
    "Nz0O_NSx4Z5q",
    "oFrO6AQv4nCQ",
    "c9tyZRNN4-4p",
    "cYhZs8Kh5Ifr",
    "8dkGiemDGZFM",
    "TMl-JzKaGU23",
    "3bDv6XIh1k-y",
    "OgiA9dnyR_Mz",
    "XcjR37Cw5bJL",
    "pU8YfanMSrtv",
    "knWwDR646F-I",
    "idFHJiPCNKqb",
    "SyF4t5-R63v0",
    "lTxpAMEnM5Lv",
    "kqDacyDTM9-c",
    "2vpNvGxOwAh7",
    "1pQqd0QMb60S",
    "DSg_c6AY4-qA",
    "kqhE7DfZzSoI"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
