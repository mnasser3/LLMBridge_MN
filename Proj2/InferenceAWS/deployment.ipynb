{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Define the IAM role with SageMaker permissions\n",
    "role = 'ENTER ROLE HERE'\n",
    "\n",
    "# Specify model data location (path to the .tar.gz file)\n",
    "model_data = 'ENTER S3 BUCKET MODEL TAR GZ LOCATION HERE'\n",
    "\n",
    "# Create the HuggingFace model object\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    entry_point='inference.py',\n",
    "    source_dir='.',  # Directory containing the inference script\n",
    "    transformers_version='4.37.0',  \n",
    "    pytorch_version='2.1.0',       \n",
    "    py_version='py310'\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Deploy the model to create the endpoint\n",
    "    print(\"Starting model deployment...\")\n",
    "    predictor = huggingface_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type='ml.m5.large',  # Use a valid CPU instance type\n",
    "        endpoint_name='marcMLT5'\n",
    "    )\n",
    "    print(\"Model deployed successfully.\")\n",
    "\n",
    "    # Wait for the endpoint to be in service\n",
    "    endpoint_name = predictor.endpoint_name\n",
    "    client = sagemaker_session.sagemaker_client\n",
    "\n",
    "    while True:\n",
    "        response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = response['EndpointStatus']\n",
    "        if status == 'InService':\n",
    "            break\n",
    "        elif status == 'Failed':\n",
    "            raise Exception(f\"Endpoint creation failed with status: {status}\")\n",
    "        print(\"Waiting for endpoint to be in service...\")\n",
    "        time.sleep(30)\n",
    "    \n",
    "    print(f\"Endpoint {endpoint_name} is in service.\")\n",
    "    print(f\"Endpoint name: {endpoint_name}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to deploy model: {str(e)}\")\n",
    "\n",
    "# Check endpoint status directly after attempting to deploy\n",
    "try:\n",
    "    client = sagemaker_session.sagemaker_client\n",
    "    response = client.describe_endpoint(EndpointName='marcMLT5')\n",
    "    status = response['EndpointStatus']\n",
    "    print(f\"Direct endpoint status check: {status}\")\n",
    "    if status == 'InService':\n",
    "        print(f\"Endpoint marcMLT5 is in service.\")\n",
    "        print(f\"Endpoint name: marcMLT5\")\n",
    "    elif status == 'Failed':\n",
    "        raise Exception(f\"Endpoint creation failed with status: {status}\")\n",
    "    else:\n",
    "        print(\"Endpoint creation is still in progress.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to check endpoint status: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "region_name = 'us-east-1'\n",
    "endpoint_name = 'marcMLT5'\n",
    "\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime', region_name=region_name)\n",
    "\n",
    "def invoke_model(input_text):\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        Body=json.dumps({'inputs': input_text})\n",
    "    )\n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    return result\n",
    "\n",
    "input_text = 955201\n",
    "output = invoke_model(input_text)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANUP\n",
    "\n",
    "import boto3\n",
    "\n",
    "# Initialize SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "def delete_endpoints():\n",
    "    # List all endpoints\n",
    "    endpoints = sagemaker_client.list_endpoints()['Endpoints']\n",
    "    for endpoint in endpoints:\n",
    "        endpoint_name = endpoint['EndpointName']\n",
    "        try:\n",
    "            sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "            print(f\"Deleted endpoint: {endpoint_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting endpoint {endpoint_name}: {e}\")\n",
    "\n",
    "def delete_endpoint_configs():\n",
    "    # List all endpoint configurations\n",
    "    endpoint_configs = sagemaker_client.list_endpoint_configs()['EndpointConfigs']\n",
    "    for config in endpoint_configs:\n",
    "        config_name = config['EndpointConfigName']\n",
    "        try:\n",
    "            sagemaker_client.delete_endpoint_config(EndpointConfigName=config_name)\n",
    "            print(f\"Deleted endpoint config: {config_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting endpoint config {config_name}: {e}\")\n",
    "\n",
    "def delete_models():\n",
    "    # List all models\n",
    "    models = sagemaker_client.list_models()['Models']\n",
    "    for model in models:\n",
    "        model_name = model['ModelName']\n",
    "        try:\n",
    "            sagemaker_client.delete_model(ModelName=model_name)\n",
    "            print(f\"Deleted model: {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting model {model_name}: {e}\")\n",
    "\n",
    "# Delete all endpoints\n",
    "delete_endpoints()\n",
    "\n",
    "# Delete all endpoint configurations\n",
    "delete_endpoint_configs()\n",
    "\n",
    "# Delete all models\n",
    "delete_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
